{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "7ebc1624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "67cd8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join,splitext\n",
    "t_dir = 'dataTrainComplete'\n",
    "txt_fnames = [splitext(f)[0] for f in listdir(t_dir) if isfile(join(t_dir, f))] #Article filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "d6bf5376",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_list = open('Keywords/02crop.list.csv', \"r\",encoding='UTF-8-sig')\n",
    "crop = crop_list.read()\n",
    "crop_line_sep = crop.splitlines()\n",
    "\n",
    "pest_list = open('Keywords/02pest.list.csv', \"r\",encoding='UTF-8-sig')\n",
    "pest = pest_list.read()\n",
    "pest_line_sep = pest.splitlines()\n",
    "\n",
    "chem_list = open('Keywords/02chem.list.csv', \"r\",encoding='UTF-8-sig')\n",
    "chem = chem_list.read()\n",
    "chem_line_sep = chem.splitlines()\n",
    "#Keywords split by lines, keyword with more than one entry will be on the same line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "9ec20f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import csv\n",
    "vector_dict = {}\n",
    "word_list = []\n",
    "#Keyword lookup with keyword as key and vector index as value\n",
    "for idx,line in enumerate(chain(crop_line_sep,pest_line_sep,chem_line_sep)):\n",
    "    l = line.split(',')\n",
    "    for word in l:\n",
    "        #Some line will have more than one entry, which should have the same vector index\n",
    "        if(word == ''):continue\n",
    "        jieba.add_word(word) #Each keyword is added to jieba\n",
    "        vector_dict[word] = l[0] # same meaning of different word will have same key number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "5e36b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding user dictionary\n",
    "userdict = ['多變', '溫差', '防檢局', '果農', '防範', '颱風', '台中市', '臺中市',\n",
    "            '發布', '發佈', '復育', '轄區', '臺南區', '開花期', '莫拉克', '桃園市', '新竹縣']\n",
    "for word in userdict:\n",
    "    jieba.add_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "553c903a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenization\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([])\n",
    "for fname in txt_fnames:\n",
    "    txt = open(t_dir+'/'+fname+'.txt', \"r\",encoding=\"utf-8\")\n",
    "    content = txt.read()\n",
    "    df = pd.concat([df, pd.Series([jieba.lcut(content, cut_all=False)])], axis = 0)\n",
    "df.columns = ['tokenization']\n",
    "df['name'] = txt_fnames\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "ac9c6960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[梅雨季, 來臨, ，, 文旦, 黑點病, 易, 發生, ，, 請, 注意, 病徵, ，, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[天氣, 多變, 溫差, 大, ，, 近山區, 及, 偏施, 氮肥, 田區, 稻熱病, 發病...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[新聞稿, -, 稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, ...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, 防治, \\n, ...</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[乍暖, 還寒, ，, 防檢局, 籲請, 農友, 加強, 防治, 稻熱病, \\n, 農委會,...</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>[苗栗, 區農業, 改良, 場, 發佈, 水稻, 白葉枯病, 警報, \\n, 糧食, 作物,...</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>[雨, 後, 適合, 稻熱病, 發生, ，, 請持續, 進行, 監測, 並指導, 農民, 防...</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>[新, 入侵, 果實蠅, 緊急, 撲滅, 模擬, 演習,  ,  , 新聞稿, \\n, 新,...</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>[梨木蝨, 危害, ，, 請, 農友, 注意, 防範, \\n, 梨木蝨, 危害, ，, 請,...</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>[防範, 梨木蝨, 危害, ，, 請, 農友, 配合, 實施, 共同, 防治, \\n, 行政...</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tokenization  name\n",
       "0    [梅雨季, 來臨, ，, 文旦, 黑點病, 易, 發生, ，, 請, 注意, 病徵, ，, ...     1\n",
       "1    [天氣, 多變, 溫差, 大, ，, 近山區, 及, 偏施, 氮肥, 田區, 稻熱病, 發病...    10\n",
       "2    [新聞稿, -, 稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, ...  1000\n",
       "3    [稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, 防治, \\n, ...  1005\n",
       "4    [乍暖, 還寒, ，, 防檢局, 籲請, 農友, 加強, 防治, 稻熱病, \\n, 農委會,...  1007\n",
       "..                                                 ...   ...\n",
       "555  [苗栗, 區農業, 改良, 場, 發佈, 水稻, 白葉枯病, 警報, \\n, 糧食, 作物,...   986\n",
       "556  [雨, 後, 適合, 稻熱病, 發生, ，, 請持續, 進行, 監測, 並指導, 農民, 防...   988\n",
       "557  [新, 入侵, 果實蠅, 緊急, 撲滅, 模擬, 演習,  ,  , 新聞稿, \\n, 新,...   992\n",
       "558  [梨木蝨, 危害, ，, 請, 農友, 注意, 防範, \\n, 梨木蝨, 危害, ，, 請,...   997\n",
       "559  [防範, 梨木蝨, 危害, ，, 請, 農友, 配合, 實施, 共同, 防治, \\n, 行政...   998\n",
       "\n",
       "[560 rows x 2 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "54f747a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the different word but have same meaning into one word\n",
    "def keyword_normalization(list_to_be_mapped, key_dict):\n",
    "    return [key_dict.get(a) if key_dict.get(a) else a for a in list_to_be_mapped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "cb2abb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping all the docs\n",
    "for index, row in df.iterrows():\n",
    "    row['tokenization'] = keyword_normalization(df.iloc[index]['tokenization'], vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "0267950f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[梅雨季, 來臨, ，, 文旦柚, 黑點病, 易, 發生, ，, 請, 注意, 病徵, ，,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[天氣, 多變, 溫差, 大, ，, 近山區, 及, 偏施, 氮肥, 田區, 稻熱病, 發病...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[新聞稿, -, 稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, ...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, 防治, \\n, ...</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[乍暖, 還寒, ，, 防檢局, 籲請, 農友, 加強, 防治, 稻熱病, \\n, 農委會,...</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>[苗栗, 區農業, 改良, 場, 發佈, 水稻, 白葉枯病, 警報, \\n, 糧食, 作物,...</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>[雨, 後, 適合, 稻熱病, 發生, ，, 請持續, 進行, 監測, 並指導, 農民, 防...</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>[新, 入侵, 果實蠅, 緊急, 撲滅, 模擬, 演習, 三泰芬, 三泰芬, 新聞稿, \\n...</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>[梨木蝨, 危害, ，, 請, 農友, 注意, 防範, \\n, 梨木蝨, 危害, ，, 請,...</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>[防範, 梨木蝨, 危害, ，, 請, 農友, 配合, 實施, 共同, 防治, \\n, 行政...</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tokenization  name\n",
       "0    [梅雨季, 來臨, ，, 文旦柚, 黑點病, 易, 發生, ，, 請, 注意, 病徵, ，,...     1\n",
       "1    [天氣, 多變, 溫差, 大, ，, 近山區, 及, 偏施, 氮肥, 田區, 稻熱病, 發病...    10\n",
       "2    [新聞稿, -, 稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, ...  1000\n",
       "3    [稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, 防治, \\n, ...  1005\n",
       "4    [乍暖, 還寒, ，, 防檢局, 籲請, 農友, 加強, 防治, 稻熱病, \\n, 農委會,...  1007\n",
       "..                                                 ...   ...\n",
       "555  [苗栗, 區農業, 改良, 場, 發佈, 水稻, 白葉枯病, 警報, \\n, 糧食, 作物,...   986\n",
       "556  [雨, 後, 適合, 稻熱病, 發生, ，, 請持續, 進行, 監測, 並指導, 農民, 防...   988\n",
       "557  [新, 入侵, 果實蠅, 緊急, 撲滅, 模擬, 演習, 三泰芬, 三泰芬, 新聞稿, \\n...   992\n",
       "558  [梨木蝨, 危害, ，, 請, 農友, 注意, 防範, \\n, 梨木蝨, 危害, ，, 請,...   997\n",
       "559  [防範, 梨木蝨, 危害, ，, 請, 農友, 配合, 實施, 共同, 防治, \\n, 行政...   998\n",
       "\n",
       "[560 rows x 2 columns]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "181f312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat tokenized text with space\n",
    "df2list = df.tokenization.tolist()\n",
    "cut_corpus = []\n",
    "for i in df2list:\n",
    "    cut_corpus.append(' '.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "9bde37a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cut_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "5c4a9bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'梅雨季 來臨 ， 文旦柚 黑點病 易 發生 ， 請 注意 病徵 ， 以及 早加強 防治 措施 。 \\n 5 月 已 進入 梅雨季 節 ， 近日 連續 降雨 ， 為 文旦柚 黑點病 開始 感染 的 時機 ， 往年 文旦柚 在 經過 4 - 6 月 的 春雨 及 梅雨季 後 ， 原來 長 得 亮麗 的 果實 外表 ， 會 開始 出現 許多 小黑 點 ， 現在 文旦柚 已 開始 進入 中果期 ， 花蓮區 農業 改良 場呼籲 應 注意 防治 。 \\n 除 冬季 清園 作業外 ， 在 4 - 8 月 時應 每月 施用 一次 56% 貝芬 硫 \\x7f 可濕性 粉劑 800 倍 、 或 22.7% \\x7f 硫 \\x7f 水懸劑 1000 倍 、 或 80% 鋅錳乃浦 500 倍 、 或 33% 鋅錳乃浦 500 倍 等 政府 核准 登記 使用 之藥劑 防治 ， 並依 登記 使用 方法 使用 ， 尤其 雨前 及雨後要 特別 加強 防治 ， 若遇 連續 降雨 時則 可 利用 間 歇 時 分區 進行 施藥 以 即 時 達 到 防治效果 。 \\n'"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "3b8af794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# functions for analysis module\n",
    "\n",
    "# CountVector\n",
    "def CountVectorizer_model(data):\n",
    "    count_vect = CountVectorizer()\n",
    "    counts = count_vect.fit_transform(data).toarray() # type: np.array\n",
    "    # names per every features: count_vect.get_feature_names(), type: list\n",
    "    return count_vect, count_vect.get_feature_names(), counts\n",
    "\n",
    "# TF-IDF\n",
    "def TfidfVectorizer_model(data):\n",
    "    tfidf_vect = TfidfVectorizer()\n",
    "    tfidfs = tfidf_vect.fit_transform(data).toarray()\n",
    "    return tfidf_vect, tfidf_vect.get_feature_names(), tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "c5f73da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Renewrr\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# for CountVectorizer module to calculate the term frequency\n",
    "count_vect, count_feature, counts = CountVectorizer_model(cut_corpus)\n",
    "# for TfidfVectorizer module to convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "tfidf_vect, tfidf_feature, tfidfs = TfidfVectorizer_model(cut_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "2d31d239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "741ef1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10646"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "ca8864da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.12346158, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.09047349, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "cb46a12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '02',\n",
       " '03',\n",
       " '037',\n",
       " '039',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '069',\n",
       " '07',\n",
       " '08',\n",
       " '0800',\n",
       " '0800039131',\n",
       " '089',\n",
       " '090',\n",
       " '0905',\n",
       " '0932',\n",
       " '0935425837',\n",
       " '095',\n",
       " '0972',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10004',\n",
       " '1000x',\n",
       " '100g',\n",
       " '101',\n",
       " '103',\n",
       " '104',\n",
       " '105',\n",
       " '1051102',\n",
       " '106',\n",
       " '108',\n",
       " '109',\n",
       " '11',\n",
       " '110',\n",
       " '118',\n",
       " '12',\n",
       " '1200',\n",
       " '12000',\n",
       " '127',\n",
       " '13',\n",
       " '130',\n",
       " '1300',\n",
       " '131',\n",
       " '139',\n",
       " '14',\n",
       " '145',\n",
       " '146',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '154',\n",
       " '1542',\n",
       " '15mm',\n",
       " '16',\n",
       " '1600',\n",
       " '1684',\n",
       " '1686',\n",
       " '17',\n",
       " '1700',\n",
       " '17512',\n",
       " '1783',\n",
       " '18',\n",
       " '1800',\n",
       " '1845',\n",
       " '19',\n",
       " '192',\n",
       " '1990',\n",
       " '1mm',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2002',\n",
       " '2006',\n",
       " '20492',\n",
       " '205',\n",
       " '206',\n",
       " '20for',\n",
       " '20japan1021226',\n",
       " '21',\n",
       " '22',\n",
       " '222111',\n",
       " '224',\n",
       " '23',\n",
       " '23431471',\n",
       " '23431473',\n",
       " '236583',\n",
       " '236619',\n",
       " '24',\n",
       " '25',\n",
       " '250',\n",
       " '2500',\n",
       " '250g',\n",
       " '251',\n",
       " '256',\n",
       " '2566',\n",
       " '26',\n",
       " '260',\n",
       " '2665',\n",
       " '2679526',\n",
       " '268',\n",
       " '27',\n",
       " '272',\n",
       " '277',\n",
       " '28',\n",
       " '29',\n",
       " '2face',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30000',\n",
       " '301',\n",
       " '302',\n",
       " '303',\n",
       " '305',\n",
       " '306',\n",
       " '307',\n",
       " '308',\n",
       " '309',\n",
       " '31',\n",
       " '310',\n",
       " '311',\n",
       " '313',\n",
       " '315',\n",
       " '32',\n",
       " '320',\n",
       " '321',\n",
       " '322046',\n",
       " '323',\n",
       " '325015',\n",
       " '325110',\n",
       " '327',\n",
       " '327904',\n",
       " '33',\n",
       " '3307',\n",
       " '333mp',\n",
       " '34',\n",
       " '35',\n",
       " '350',\n",
       " '351',\n",
       " '358616',\n",
       " '358618',\n",
       " '36',\n",
       " '360',\n",
       " '3600',\n",
       " '361786',\n",
       " '3691ctnode',\n",
       " '37',\n",
       " '370',\n",
       " '3751574',\n",
       " '38',\n",
       " '382',\n",
       " '39',\n",
       " '390',\n",
       " '3mm',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '409',\n",
       " '41',\n",
       " '411',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '441',\n",
       " '443',\n",
       " '45',\n",
       " '450',\n",
       " '46',\n",
       " '460',\n",
       " '47',\n",
       " '476',\n",
       " '4768216',\n",
       " '48',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '500g',\n",
       " '52',\n",
       " '525g',\n",
       " '526',\n",
       " '53',\n",
       " '53715',\n",
       " '5371574',\n",
       " '54',\n",
       " '5400',\n",
       " '55',\n",
       " '552',\n",
       " '5523270',\n",
       " '5523307',\n",
       " '558124',\n",
       " '56',\n",
       " '58',\n",
       " '590',\n",
       " '5912901',\n",
       " '5912905',\n",
       " '5x10',\n",
       " '60',\n",
       " '600',\n",
       " '6000',\n",
       " '61',\n",
       " '613',\n",
       " '62',\n",
       " '63',\n",
       " '632',\n",
       " '634',\n",
       " '64',\n",
       " '65',\n",
       " '650',\n",
       " '6622274',\n",
       " '67',\n",
       " '68',\n",
       " '683',\n",
       " '70',\n",
       " '700',\n",
       " '700pcu',\n",
       " '71',\n",
       " '72',\n",
       " '72000',\n",
       " '7229461',\n",
       " '73',\n",
       " '730',\n",
       " '73000',\n",
       " '737',\n",
       " '738',\n",
       " '7389060',\n",
       " '7389158',\n",
       " '74',\n",
       " '744',\n",
       " '75',\n",
       " '750',\n",
       " '7500',\n",
       " '76',\n",
       " '7642',\n",
       " '7665',\n",
       " '7665page',\n",
       " '77',\n",
       " '7746728',\n",
       " '7746741',\n",
       " '7746755',\n",
       " '7746761',\n",
       " '78',\n",
       " '79',\n",
       " '7cfu',\n",
       " '7g',\n",
       " '80',\n",
       " '800',\n",
       " '8000',\n",
       " '81',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '850',\n",
       " '8521108',\n",
       " '8521114',\n",
       " '8521493',\n",
       " '8535915',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '880',\n",
       " '89',\n",
       " '90',\n",
       " '900',\n",
       " '901',\n",
       " '9030',\n",
       " '9031',\n",
       " '9060',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '9632',\n",
       " '97',\n",
       " '977',\n",
       " '98',\n",
       " '9899739',\n",
       " '99',\n",
       " '9cfu',\n",
       " 'acerialitchi',\n",
       " 'ageratumyellowveinvirus',\n",
       " 'agral',\n",
       " 'annonasquamosa',\n",
       " 'anonaepestisbengalella',\n",
       " 'aphiq',\n",
       " 'app',\n",
       " 'articles',\n",
       " 'aspx',\n",
       " 'ayvv',\n",
       " 'banana',\n",
       " 'baphig',\n",
       " 'baphiq',\n",
       " 'blackrotofpapaya',\n",
       " 'c3',\n",
       " 'catid',\n",
       " 'cmv',\n",
       " 'coa',\n",
       " 'cs',\n",
       " 'ct',\n",
       " 'cucumbermosaicvirus',\n",
       " 'drug',\n",
       " 'dug',\n",
       " 'faw',\n",
       " 'file',\n",
       " 'filelink1fontsize',\n",
       " 'fontdivid',\n",
       " 'formmap',\n",
       " 'fp2000',\n",
       " 'fusariummangiferae',\n",
       " 'g1',\n",
       " 'googlemap',\n",
       " 'gov',\n",
       " 'hdais',\n",
       " 'hdares',\n",
       " 'htdocs',\n",
       " 'htm',\n",
       " 'htmlarea',\n",
       " 'http',\n",
       " 'https',\n",
       " 'id',\n",
       " 'index',\n",
       " 'insecticides',\n",
       " 'kdais',\n",
       " 'keifer',\n",
       " 'line',\n",
       " 'linfa',\n",
       " 'list',\n",
       " 'longanwitchsbroom',\n",
       " 'longwang',\n",
       " 'mango',\n",
       " 'mango1020812',\n",
       " 'mdaes',\n",
       " 'mdais',\n",
       " 'menuitem1',\n",
       " 'menuitem5',\n",
       " 'meskell',\n",
       " 'mm',\n",
       " 'news',\n",
       " 'newsdetailviews',\n",
       " 'nsf',\n",
       " 'openform',\n",
       " 'org',\n",
       " 'otserv2',\n",
       " 'pdf',\n",
       " 'pe',\n",
       " 'peronophythoralitchii',\n",
       " 'pess',\n",
       " 'pesticide',\n",
       " 'ph6',\n",
       " 'philusantennatus',\n",
       " 'phis',\n",
       " 'php',\n",
       " 'phyllotretastriolata',\n",
       " 'phytoplasma',\n",
       " 'planococcusminor',\n",
       " 'plant',\n",
       " 'porbenazole',\n",
       " 'potatovirusy',\n",
       " 'potect',\n",
       " 'ppm',\n",
       " 'ppmtable',\n",
       " 'ppmtale',\n",
       " 'prevention',\n",
       " 'protect',\n",
       " 'pseudomonassyringae',\n",
       " 'pvy',\n",
       " 'pythium',\n",
       " 'pythiumspp',\n",
       " 'rhizoctonia',\n",
       " 'rhizoctoniasolani',\n",
       " 'riced',\n",
       " 'rid',\n",
       " 'scirtothripsdorsalis',\n",
       " 'sn',\n",
       " 'streptomycin',\n",
       " 'sug',\n",
       " 'tacti',\n",
       " 'tactri',\n",
       " 'tdais',\n",
       " 'tecloftalam',\n",
       " 'tetracycline',\n",
       " 'theme',\n",
       " 'tndais',\n",
       " 'tomatomosaicvirus',\n",
       " 'tomatospottedwiltvirus',\n",
       " 'tomatoyellowleafcurlvirus',\n",
       " 'tomv',\n",
       " 'tswv',\n",
       " 'tw',\n",
       " 'tylcv',\n",
       " 'vesicatoria',\n",
       " 'view',\n",
       " 'we',\n",
       " 'web',\n",
       " 'webevery',\n",
       " 'wp1500',\n",
       " 'ws',\n",
       " 'wsite',\n",
       " 'www',\n",
       " 'xanthomonascampestrispv',\n",
       " 'xitem',\n",
       " '一久',\n",
       " '一二',\n",
       " '一五',\n",
       " '一些',\n",
       " '一個',\n",
       " '一個蟲',\n",
       " '一傳真',\n",
       " '一傷口',\n",
       " '一公頃',\n",
       " '一六號',\n",
       " '一分',\n",
       " '一則',\n",
       " '一千一百',\n",
       " '一千零五',\n",
       " '一半',\n",
       " '一圈',\n",
       " '一堆',\n",
       " '一大',\n",
       " '一天',\n",
       " '一季',\n",
       " '一定',\n",
       " '一害蟲',\n",
       " '一小',\n",
       " '一層',\n",
       " '一帶',\n",
       " '一年',\n",
       " '一幼葉',\n",
       " '一排',\n",
       " '一斑',\n",
       " '一日',\n",
       " '一旦',\n",
       " '一時',\n",
       " '一期',\n",
       " '一期稻作',\n",
       " '一果',\n",
       " '一株',\n",
       " '一條',\n",
       " '一次',\n",
       " '一步',\n",
       " '一段',\n",
       " '一波',\n",
       " '一波接',\n",
       " '一波鋒面',\n",
       " '一片',\n",
       " '一生',\n",
       " '一百',\n",
       " '一百五十',\n",
       " '一直',\n",
       " '一種',\n",
       " '一級',\n",
       " '一致',\n",
       " '一般',\n",
       " '一般而言',\n",
       " '一蟲',\n",
       " '一行',\n",
       " '一賃',\n",
       " '一起',\n",
       " '一路',\n",
       " '一輪',\n",
       " '一連',\n",
       " '一週',\n",
       " '一邊',\n",
       " '一鉀',\n",
       " '一鐵樹',\n",
       " '一陣',\n",
       " '一面',\n",
       " '一項',\n",
       " '一點',\n",
       " '一齡',\n",
       " '丁基加保扶',\n",
       " '七五',\n",
       " '七分',\n",
       " '七天',\n",
       " '七年',\n",
       " '七張',\n",
       " '七日',\n",
       " '七月',\n",
       " '七股',\n",
       " '七至',\n",
       " '七路',\n",
       " '三一',\n",
       " '三個',\n",
       " '三元',\n",
       " '三元硫酸銅',\n",
       " '三到',\n",
       " '三則',\n",
       " '三化螟',\n",
       " '三十',\n",
       " '三十五',\n",
       " '三十度',\n",
       " '三十日',\n",
       " '三千',\n",
       " '三四',\n",
       " '三塞唑',\n",
       " '三大',\n",
       " '三層',\n",
       " '三得芬',\n",
       " '三星',\n",
       " '三月',\n",
       " '三次',\n",
       " '三民',\n",
       " '三氟敏',\n",
       " '三氟派瑞',\n",
       " '三氯松',\n",
       " '三泰芬',\n",
       " '三泰隆',\n",
       " '三灣',\n",
       " '三片',\n",
       " '三種',\n",
       " '三縣',\n",
       " '三至',\n",
       " '三處',\n",
       " '三要素',\n",
       " '三變',\n",
       " '三賽唑',\n",
       " '三路',\n",
       " '三週',\n",
       " '三項',\n",
       " '三齡',\n",
       " '上下',\n",
       " '上並',\n",
       " '上之病',\n",
       " '上令',\n",
       " '上以',\n",
       " '上位',\n",
       " '上傳',\n",
       " '上出',\n",
       " '上列',\n",
       " '上則',\n",
       " '上化',\n",
       " '上升',\n",
       " '上午',\n",
       " '上及',\n",
       " '上噴',\n",
       " '上均',\n",
       " '上市',\n",
       " '上常',\n",
       " '上應',\n",
       " '上方',\n",
       " '上旬',\n",
       " '上會出',\n",
       " '上會產生',\n",
       " '上產卵',\n",
       " '上產生',\n",
       " '上病',\n",
       " '上移',\n",
       " '上端',\n",
       " '上策',\n",
       " '上經',\n",
       " '上維持',\n",
       " '上網',\n",
       " '上要',\n",
       " '上覆',\n",
       " '上轉',\n",
       " '上述',\n",
       " '上部',\n",
       " '上除',\n",
       " '上須',\n",
       " '上黃化',\n",
       " '下一代',\n",
       " '下位',\n",
       " '下供',\n",
       " '下列',\n",
       " '下午',\n",
       " '下半年',\n",
       " '下均',\n",
       " '下垂',\n",
       " '下將',\n",
       " '下山',\n",
       " '下己',\n",
       " '下播種',\n",
       " '下方',\n",
       " '下旬',\n",
       " '下易',\n",
       " '下易產生',\n",
       " '下會',\n",
       " '下會產生',\n",
       " '下期',\n",
       " '下極',\n",
       " '下次',\n",
       " '下產生',\n",
       " '下田',\n",
       " '下端',\n",
       " '下葉鞘',\n",
       " '下藥',\n",
       " '下表',\n",
       " '下表中',\n",
       " '下載',\n",
       " '下述',\n",
       " '下部',\n",
       " '下開',\n",
       " '下降',\n",
       " '下陷',\n",
       " '下雨',\n",
       " '下面',\n",
       " '不下',\n",
       " '不久',\n",
       " '不予',\n",
       " '不二',\n",
       " '不但',\n",
       " '不佳',\n",
       " '不佳及',\n",
       " '不佳時',\n",
       " '不來',\n",
       " '不僅',\n",
       " '不像',\n",
       " '不償失',\n",
       " '不全',\n",
       " '不具',\n",
       " '不再',\n",
       " '不利',\n",
       " '不到',\n",
       " '不勾頭',\n",
       " '不及',\n",
       " '不可',\n",
       " '不同',\n",
       " '不善',\n",
       " '不堪',\n",
       " '不外乎',\n",
       " '不大',\n",
       " '不如',\n",
       " '不定',\n",
       " '不宜',\n",
       " '不容',\n",
       " '不少',\n",
       " '不展',\n",
       " '不常見',\n",
       " '不建議',\n",
       " '不得',\n",
       " '不必',\n",
       " '不慎',\n",
       " '不應',\n",
       " '不持續',\n",
       " '不整',\n",
       " '不斷',\n",
       " '不明',\n",
       " '不易',\n",
       " '不是',\n",
       " '不時',\n",
       " '不會',\n",
       " '不會產生',\n",
       " '不會重',\n",
       " '不正',\n",
       " '不用',\n",
       " '不當',\n",
       " '不盡',\n",
       " '不稔',\n",
       " '不管',\n",
       " '不絕',\n",
       " '不織布',\n",
       " '不能',\n",
       " '不致',\n",
       " '不良',\n",
       " '不著果',\n",
       " '不表現',\n",
       " '不要',\n",
       " '不見',\n",
       " '不規則',\n",
       " '不論',\n",
       " '不論行',\n",
       " '不足',\n",
       " '不通',\n",
       " '不過',\n",
       " '不過量',\n",
       " '不遠',\n",
       " '不錯',\n",
       " '不間',\n",
       " '不飛翔',\n",
       " '不飽滿',\n",
       " '不高',\n",
       " '且僅',\n",
       " '且務必',\n",
       " '且慢',\n",
       " '且施',\n",
       " '且易',\n",
       " '且易降',\n",
       " '且晨間',\n",
       " '且會',\n",
       " '且果',\n",
       " '且現',\n",
       " '且逢蕉株',\n",
       " '且須',\n",
       " '世代',\n",
       " '世界',\n",
       " '世界性',\n",
       " '世紀',\n",
       " '丙基喜樂松',\n",
       " '丟棄',\n",
       " '並上',\n",
       " '並不',\n",
       " '並不發生',\n",
       " '並不顯',\n",
       " '並且',\n",
       " '並仔細',\n",
       " '並仔細將',\n",
       " '並以',\n",
       " '並使',\n",
       " '並依',\n",
       " '並依其',\n",
       " '並依據',\n",
       " '並保護',\n",
       " '並保護天',\n",
       " '並傳',\n",
       " '並傳播',\n",
       " '並出',\n",
       " '並出現',\n",
       " '並分次',\n",
       " '並加',\n",
       " '並加強',\n",
       " '並勇',\n",
       " '並務',\n",
       " '並務必',\n",
       " '並勿',\n",
       " '並參考',\n",
       " '並及',\n",
       " '並可',\n",
       " '並可作',\n",
       " '並同時',\n",
       " '並向',\n",
       " '並向果',\n",
       " '並呈萎',\n",
       " '並噴施',\n",
       " '並嚴',\n",
       " '並嚴格',\n",
       " '並因',\n",
       " '並在',\n",
       " '並在種',\n",
       " '並在終',\n",
       " '並均勻',\n",
       " '並增',\n",
       " '並委由清',\n",
       " '並宜',\n",
       " '並將',\n",
       " '並將果',\n",
       " '並將藥',\n",
       " '並已',\n",
       " '並常圍',\n",
       " '並常腫',\n",
       " '並建議',\n",
       " '並影響',\n",
       " '並從病',\n",
       " '並徹底',\n",
       " '並應',\n",
       " '並應加',\n",
       " '並應用',\n",
       " '並懸掛',\n",
       " '並持續',\n",
       " '並指導',\n",
       " '並採',\n",
       " '並採取',\n",
       " '並散',\n",
       " '並於一',\n",
       " '並於主幹',\n",
       " '並於後續',\n",
       " '並於採',\n",
       " '並於施藥',\n",
       " '並於果',\n",
       " '並於田間',\n",
       " '並於終',\n",
       " '並於開',\n",
       " '並曝曬',\n",
       " '並曾',\n",
       " '並會',\n",
       " '並會長',\n",
       " '並有',\n",
       " '並未',\n",
       " '並每',\n",
       " '並決定',\n",
       " '並流膠',\n",
       " '並減',\n",
       " '並潛伏',\n",
       " '並無',\n",
       " '並無抗',\n",
       " '並無攜',\n",
       " '並無黃色',\n",
       " '並燒',\n",
       " '並特別',\n",
       " '並產',\n",
       " '並產卵',\n",
       " '並產生',\n",
       " '並盡量',\n",
       " '並確',\n",
       " '並確切',\n",
       " '並確實',\n",
       " '並立',\n",
       " '並給予',\n",
       " '並聯合',\n",
       " '並自',\n",
       " '並與',\n",
       " '並與縣',\n",
       " '並行',\n",
       " '並補施',\n",
       " '並補植',\n",
       " '並褐化',\n",
       " '並視',\n",
       " '並請',\n",
       " '並請務必',\n",
       " '並輪流',\n",
       " '並輪用',\n",
       " '並轉',\n",
       " '並逐漸',\n",
       " '並通報',\n",
       " '並進',\n",
       " '並進入',\n",
       " '並進行',\n",
       " '並達',\n",
       " '並適',\n",
       " '並適法',\n",
       " '並適當',\n",
       " '並適量',\n",
       " '並選',\n",
       " '並選擇',\n",
       " '並選用',\n",
       " '並選留',\n",
       " '並避開',\n",
       " '並酌',\n",
       " '並針',\n",
       " '並長',\n",
       " '並關閉',\n",
       " '並隨即',\n",
       " '並隨時',\n",
       " '並隨葉脈',\n",
       " '並需',\n",
       " '並非',\n",
       " '並食',\n",
       " '並鼓勵',\n",
       " '中下旬',\n",
       " '中之卵',\n",
       " '中之果',\n",
       " '中之落',\n",
       " '中以',\n",
       " '中任',\n",
       " '中作',\n",
       " '中供',\n",
       " '中化',\n",
       " '中北部',\n",
       " '中區',\n",
       " '中午',\n",
       " '中南部',\n",
       " '中及',\n",
       " '中和液',\n",
       " '中噴藥',\n",
       " '中埔',\n",
       " '中場',\n",
       " '中場籲',\n",
       " '中大果期',\n",
       " '中央',\n",
       " '中始',\n",
       " '中小',\n",
       " '中常',\n",
       " '中度',\n",
       " '中往',\n",
       " '中後期',\n",
       " '中心',\n",
       " '中所',\n",
       " '中抗',\n",
       " '中旬',\n",
       " '中是',\n",
       " '中期',\n",
       " '中果',\n",
       " '中果期',\n",
       " '中株',\n",
       " '中株期',\n",
       " '中殘留',\n",
       " '中段',\n",
       " '中毒',\n",
       " '中水',\n",
       " '中產卵',\n",
       " '中秋',\n",
       " '中等',\n",
       " '中籲',\n",
       " '中結',\n",
       " '中縣',\n",
       " '中脈',\n",
       " '中華民國',\n",
       " '中蕉',\n",
       " '中該',\n",
       " '中誘',\n",
       " '中農',\n",
       " '中達',\n",
       " '中部',\n",
       " '中針',\n",
       " '中間',\n",
       " '中闊',\n",
       " '中髓',\n",
       " '串飽度',\n",
       " '主動',\n",
       " '主因',\n",
       " '主幹',\n",
       " '主幹樹',\n",
       " '主持人',\n",
       " '主梗穗',\n",
       " '主產區',\n",
       " '主管',\n",
       " '主脈',\n",
       " '主要',\n",
       " '主辦',\n",
       " '乃力松',\n",
       " '乃是',\n",
       " '乃為',\n",
       " '久旱',\n",
       " '久旱不雨',\n",
       " '之一',\n",
       " '之下',\n",
       " '之中',\n",
       " '之久',\n",
       " '之以',\n",
       " '之依據',\n",
       " '之側',\n",
       " '之傳播',\n",
       " '之傳染',\n",
       " '之前',\n",
       " '之劑',\n",
       " '之務為',\n",
       " '之區域',\n",
       " '之協助',\n",
       " '之卵',\n",
       " '之卵粒',\n",
       " '之品',\n",
       " '之品種',\n",
       " '之品質',\n",
       " '之園區',\n",
       " '之圓圈',\n",
       " '之圓形',\n",
       " '之土',\n",
       " '之報',\n",
       " '之場',\n",
       " '之夏',\n",
       " '之夏蕉',\n",
       " '之外',\n",
       " '之大',\n",
       " '之天',\n",
       " '之好',\n",
       " '之季節',\n",
       " '之害蟲',\n",
       " '之小果',\n",
       " '之小點',\n",
       " '之展',\n",
       " '之山區',\n",
       " '之帶',\n",
       " '之幼蟲',\n",
       " '之後再',\n",
       " '之後擴',\n",
       " '之後轉',\n",
       " '之感病',\n",
       " '之成',\n",
       " '之成敗',\n",
       " '之成蟲',\n",
       " '之效',\n",
       " '之明',\n",
       " '之明顯',\n",
       " '之時',\n",
       " '之時期',\n",
       " '之時間',\n",
       " '之有',\n",
       " '之木',\n",
       " '之果',\n",
       " '之果園',\n",
       " '之果實',\n",
       " '之枝條',\n",
       " '之根際',\n",
       " '之桃園',\n",
       " '之梨穗',\n",
       " '之毒',\n",
       " '之氣候',\n",
       " '之氣溫',\n",
       " '之災害',\n",
       " '之為害',\n",
       " '之環境',\n",
       " '之生',\n",
       " '之生長',\n",
       " '之產生',\n",
       " '之產量',\n",
       " '之用',\n",
       " '之田區',\n",
       " '之田區須',\n",
       " '之田園',\n",
       " '之田間',\n",
       " '之病',\n",
       " '之登',\n",
       " '之登記',\n",
       " '之發',\n",
       " '之省',\n",
       " '之秧',\n",
       " '之稀釋',\n",
       " '之稔',\n",
       " '之種',\n",
       " '之稻',\n",
       " '之粒劑',\n",
       " '之系',\n",
       " '之細菌性',\n",
       " '之細長',\n",
       " '之經濟',\n",
       " '之緊',\n",
       " '之花穗',\n",
       " ...]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "ebe26f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from scipy import spatial\n",
    "## setting\n",
    "vector_dim = 200\n",
    "window_size = 5\n",
    "min_count = 1\n",
    "training_iter = 20\n",
    "\n",
    "## model\n",
    "word2vec_model = Word2Vec(sentences=df2list,\n",
    "                          vector_size=vector_dim, window=window_size, \n",
    "                          min_count=min_count, epochs=training_iter)\n",
    "# index to word\n",
    "index_to_word = word2vec_model.wv.index_to_key  # len(word2vec_model.wv.index2word) = 8659\n",
    "# index to vectors\n",
    "index2vec = word2vec_model.wv.vectors # word2vec_model.wv.vectors.shape = (8659, 100)\n",
    "\n",
    "def preprocess(s):\n",
    "    return [i.lower() for i in s.split()]\n",
    "def get_vector(s):\n",
    "    for i in preprocess(s):\n",
    "        try:\n",
    "            values = np.sum(np.array([word2vec_model.wv[i]]), axis=0)#Change\n",
    "        except KeyError:\n",
    "            c = 0\n",
    "    return values\n",
    "\n",
    "word2vec_feature = np.array([])\n",
    "for i in np.arange(len(cut_corpus)):\n",
    "    if word2vec_feature.size == 0:\n",
    "        word2vec_feature = np.array([get_vector(cut_corpus[i])])\n",
    "    else:\n",
    "        # concat the two vectors by different columns\n",
    "        word2vec_feature = np.concatenate((word2vec_feature,np.array([get_vector(cut_corpus[i])])), axis = 0)\n",
    "\n",
    "# word2vec_feature.shape = (560, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "819e8a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313040\n",
      "1383\n",
      "313040\n"
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "pair_list = []\n",
    "#Deprecated\n",
    "for fname1 in txt_fnames:\n",
    "    for fname2 in txt_fnames:\n",
    "        if(fname1 == fname2):continue\n",
    "        else:\n",
    "            labels[(fname1,fname2)] = 0\n",
    "            pair_list.append((fname1,fname2))\n",
    "corr_list = open('TrainLabel.csv', \"r\",encoding='UTF-8-sig')\n",
    "corr = corr_list.read()\n",
    "corr_line_sep = corr.splitlines()\n",
    "#Training label\n",
    "for line in corr_line_sep[1:]:\n",
    "    l = line.split(',')\n",
    "    labels[(l[0],l[1])] = 1\n",
    "print(len(labels))\n",
    "print(sum(labels.values()))\n",
    "print(len(pair_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "95a21fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313040\n"
     ]
    }
   ],
   "source": [
    "pos_pair_list = []\n",
    "pos_labels = set() #faster lookup to filter out positive pairs, not used elsewhere\n",
    "#All the associated article pairs given by train label\n",
    "for line in corr_line_sep[1:]:\n",
    "    l = line.split(',')\n",
    "    pos_pair_list.append((l[0],l[1]))\n",
    "    pos_labels.add((l[0],l[1]))\n",
    "neg_pair_list = []\n",
    "#Other pairs with no association\n",
    "for fname1 in txt_fnames:\n",
    "    for fname2 in txt_fnames:\n",
    "        if(fname1 == fname2):continue\n",
    "        if((fname1,fname2) not in pos_labels): #Filter out positive pairs\n",
    "            neg_pair_list.append((fname1,fname2))\n",
    "print(len(pos_pair_list)+len(neg_pair_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "8d43ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# decide which feature you want, tfidf or countvector or others\n",
    "def construct_input_vector(adapted_vector, tokenized_df, pos_pair_list, neg_pair_list):\n",
    "    pl = len(pos_pair_list) # Number of positive pairs\n",
    "    neg_keys = random.sample(neg_pair_list,pl) # same length of negative pairs\n",
    "    sample_labels = {}\n",
    "    for key in neg_keys:sample_labels[key] = 0\n",
    "    for key in pos_pair_list:sample_labels[key] = 1\n",
    "    sample_pair_list = pos_pair_list + neg_keys\n",
    "    sample_labels_list = []\n",
    "    input_vectors = np.array([])\n",
    "    for i in np.arange(len(sample_pair_list)):\n",
    "        Test, Ref = sample_pair_list[i] # order of docs\n",
    "        sample_labels_list.append(sample_labels[(Test,Ref)]) # labels\n",
    "        Test_vec = adapted_vector[tokenized_df[tokenized_df['name']==Test].index[0]] # from order of doc to find out the order of vectors\n",
    "        Ref_vec = adapted_vector[tokenized_df[tokenized_df['name']==Ref].index[0]] # same\n",
    "        temp_vectors = np.concatenate(([Test_vec],[Ref_vec]), axis = 1) # concat the two vectors in same row\n",
    "        if input_vectors.size == 0:\n",
    "            input_vectors = temp_vectors\n",
    "        else:\n",
    "            input_vectors = np.concatenate((input_vectors,temp_vectors)) # concat the two vectors by different columns\n",
    "    return input_vectors, sample_labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75664f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vectors0, sample_labels_list0 = construct_input_vector(tfidfs, df, pos_pair_list, neg_pair_list)\n",
    "# input_vectors0.shape, len(sample_labels_list0) = (2766, 15122), 2766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0901bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vectors1, sample_labels_list1 = construct_input_vector(counts, df, pos_pair_list, neg_pair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "146af23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vectors2, sample_labels_list2 = construct_input_vector(word2vec_feature, df, pos_pair_list, neg_pair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97d54cdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1284/852056315.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# using these code as embedding features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform',\n\u001b[0m\u001b[0;32m      3\u001b[0m                        \u001b[0membeddings_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                        embeddings_constraint=None, mask_zero=False, input_length=None)\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex2vec\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# using these code as embedding features\n",
    "keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform',\n",
    "                       embeddings_regularizer=None, activity_regularizer=None,\n",
    "                       embeddings_constraint=None, mask_zero=False, input_length=None)\n",
    "model.add(Embedding(index2vec.shape[0], index2vec.shape[1], weights=[index2vec], trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "fd1915ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 10646)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vectors0.shape,input_vectors1.shape,input_vectors2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a70b1",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "c0aee5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560\n",
      "560\n",
      "560\n"
     ]
    }
   ],
   "source": [
    "df.iloc[0]['name']\n",
    "tfidf_dict = {}\n",
    "for idx,vec in enumerate(tfidfs):\n",
    "    tfidf_dict[df.iloc[idx]['name']] = vec\n",
    "print(len(tfidf_dict))\n",
    "w2v_dict = {}\n",
    "for idx,vec in enumerate(word2vec_feature):\n",
    "    w2v_dict[df.iloc[idx]['name']] = vec\n",
    "print(len(w2v_dict))\n",
    "counts_dict = {}\n",
    "for idx,vec in enumerate(counts):\n",
    "    counts_dict[df.iloc[idx]['name']] = vec\n",
    "print(len(counts_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "d8d908b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "# Dataset\n",
    "#Custom dataset, currently generates a 50/50 split of positive and negative sample\n",
    "#To change the split, change the second variable of random.sample and the __len__ function accordingly\n",
    "class PartDataset(data.Dataset):\n",
    "    def __init__(self, pos_pair_list, neg_pair_list, vectors):\n",
    "        self.l = len(pos_pair_list)#Number of positive pairs\n",
    "        neg_keys = random.sample(neg_pair_list,self.l)#Sample negative pairs, change the second variable to change the split\n",
    "        self.labels = {}\n",
    "        for key in neg_keys:self.labels[key] = 0\n",
    "        for key in pos_pair_list:self.labels[key] = 1\n",
    "        self.pair_list = pos_pair_list+neg_keys\n",
    "        self.vectors = vectors\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.l*2\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        Test,Ref = self.pair_list[idx]\n",
    "        label = self.labels[(Test,Ref)]\n",
    "        #comb_vector = self.vectors[Test] + self.vectors[Ref]\n",
    "        comb_vector = np.concatenate((self.vectors[Test], self.vectors[Ref]), axis=None)\n",
    "        return torch.tensor(comb_vector), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "5f2fd099",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdim_tfidf = len(tfidfs[0])\n",
    "class TfIdfNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TfIdfNeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(inputdim_tfidf*2, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 56),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(56, 2),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "inputdim_w2v = len(word2vec_feature[0])\n",
    "class w2vNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(w2vNeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(inputdim_w2v*2, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(50, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(20, 2),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "06b24d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PartDataset(pos_pair_list, neg_pair_list, tfidf_dict)\n",
    "test_dataset = PartDataset(pos_pair_list, neg_pair_list, tfidf_dict)\n",
    "#train_dataset = PartDataset(pos_pair_list, neg_pair_list, w2v_dict)\n",
    "#test_dataset = PartDataset(pos_pair_list, neg_pair_list, w2v_dict)\n",
    "#train_dataset = PartDataset(pos_pair_list, neg_pair_list, counts_dict)\n",
    "#test_dataset = PartDataset(pos_pair_list, neg_pair_list, counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "b896f785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Check\n"
     ]
    }
   ],
   "source": [
    "tfidf_train_dataloader = data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "tfidf_test_dataloader = data.DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "tfidf_dataloader_dict = {'train': tfidf_train_dataloader, 'test': tfidf_test_dataloader}\n",
    "\n",
    "# Operation Check\n",
    "print('Operation Check')\n",
    "batch_iterator = iter(tfidf_train_dataloader)\n",
    "inputs, label = next(batch_iterator)\n",
    "#print(label,inputs[0][0:200]==inputs[0][200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "4c347642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfIdfNeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=21292, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=56, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=56, out_features=2, bias=True)\n",
      "    (10): Softmax(dim=None)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = TfIdfNeuralNetwork()\n",
    "#net = w2vNeuralNetwork()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=0.001, momentum=0.9)\n",
    "#cross entropy loss and stochastic gradient descent\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "9af65130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def train_model(net, dataloader_dict, criterion, optimizer, num_epoch):\n",
    "    \n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(net.state_dict())\n",
    "    best_acc = 0.0\n",
    "    net = net.to(device)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epoch))\n",
    "        print('-'*20)\n",
    "        \n",
    "        for phase in ['train', 'test']:\n",
    "            \n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "                \n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "            \n",
    "            #tqdm for progress bar\n",
    "            for inputs, labels in tqdm(dataloader_dict[phase]):\n",
    "                inputs = inputs.type(torch.FloatTensor).to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = net(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "                    \n",
    "            epoch_loss = epoch_loss / len(dataloader_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloader_dict[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(net.state_dict())\n",
    "                print(time.time())\n",
    "                torch.save(net.state_dict(), 'best_checkpoint_last_TFIDF.pth')\n",
    "                \n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    net.load_state_dict(best_model_wts)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "efa3a7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fac8690ab3a48beab3df5bfc901936c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6937 Acc: 0.4989\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf0db05275b4364bfe24663ba2258ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6933 Acc: 0.5000\n",
      "1639384508.127628\n",
      "Epoch 2/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144373115f124c1087867ffa045bc88e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6934 Acc: 0.4899\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fb05699f0f46dab156f8609051dda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6931 Acc: 0.5000\n",
      "Epoch 3/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dcd0ba190bc45c4a729dd8c56383e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6932 Acc: 0.5025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde86a094a464d08b49b27c46949be20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6930 Acc: 0.5000\n",
      "Epoch 4/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc0ea981ab34ead8fb6139126d84418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6930 Acc: 0.5061\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369da6e7ce8b487a88d420eb547d9991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6929 Acc: 0.5000\n",
      "Epoch 5/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae75746990b24d638a52ac008a831d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6930 Acc: 0.5119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babe03b498024b3baa24806969fd440a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6928 Acc: 0.5000\n",
      "Epoch 6/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb08ee81872496dab9e2f7edbc261e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6929 Acc: 0.5260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd35af638e046a8ab96d0581413b009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6927 Acc: 0.6970\n",
      "1639384572.1051893\n",
      "Epoch 7/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3af1d405b7477e9252c73e930f7693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6928 Acc: 0.5181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10b7ee504544624a6caff54f1f13a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6926 Acc: 0.5000\n",
      "Epoch 8/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f210bb3bd1436488dc56b8b5ec17f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6926 Acc: 0.5325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1771f6117594fa08bcf2219ce00ab04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6924 Acc: 0.6652\n",
      "Epoch 9/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f164c435e39c42909fc8e1265fe4fa3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6924 Acc: 0.5325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107b8780c5984593b9032bf36e7a2fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6922 Acc: 0.5000\n",
      "Epoch 10/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcf73dd9f7742f59fe73dc3f64ea196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6923 Acc: 0.5557\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec411319793242bdb69e2b8dd21cf5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6920 Acc: 0.5000\n",
      "Epoch 11/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64a7e33b81140a7b671f9259dc14cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6920 Acc: 0.5076\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a48ac6d7d4b4536a626d08104816850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6916 Acc: 0.6999\n",
      "1639384636.149301\n",
      "Epoch 12/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ee9214c9774922bf6188ae71bc63af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6914 Acc: 0.5965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f93376f6e1349c085da1444f0c0e382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6911 Acc: 0.6941\n",
      "Epoch 13/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60a8e628e88487c8c80045c20de1801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6909 Acc: 0.6392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596bcca945454ae681ca5d6e41371aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6904 Acc: 0.6988\n",
      "Epoch 14/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e95fe3b5a34a14b974a684d9d5c9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6900 Acc: 0.6298\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7562a834728e4d6d8323e6d2e163e4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6893 Acc: 0.6580\n",
      "Epoch 15/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9706404edf5e46eba99a8b32e3d6bbc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6884 Acc: 0.6688\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f48978210e46399b1c93e6709ba7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6875 Acc: 0.6862\n",
      "Epoch 16/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db75d4a50ac440ab8afad7ef04ec826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6860 Acc: 0.6352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e83ad34f3664f978fe34a9ddef82321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6844 Acc: 0.7111\n",
      "1639384703.0954645\n",
      "Epoch 17/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536021a93a334a8198df4af45235d8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6815 Acc: 0.7050\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345f9333d8c54f81b8519ffa543ffba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6783 Acc: 0.7054\n",
      "Epoch 18/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c128187ec43492aacac42c9da2e318b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6725 Acc: 0.7104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f00b2b9395428d9272a8c1e29f9dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6659 Acc: 0.7260\n",
      "1639384729.3248913\n",
      "Epoch 19/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0339b6fb2b6740e18e281b662e0cacaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6535 Acc: 0.7242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09240f27781a46a890827842a169e907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6398 Acc: 0.7140\n",
      "Epoch 20/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96901bc5121947489a948494d516b520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6170 Acc: 0.7426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64169ca228d341578c80f0fbca723cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5990 Acc: 0.7375\n",
      "1639384755.6632469\n",
      "Epoch 21/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430fa770d66c4040a48c3f655b083a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5746 Acc: 0.7693\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17687fb04d74da79ded7ef6cee62217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5641 Acc: 0.7581\n",
      "1639384770.1679895\n",
      "Epoch 22/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0588c544b33b4fd2a23d61ded0d3013f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5395 Acc: 0.7921\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cb33de215e49e29506fad42ccca3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5330 Acc: 0.7899\n",
      "1639384784.451025\n",
      "Epoch 23/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbab18d017004f11abfa394a8976e417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5128 Acc: 0.8142\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6b71f8181e40699b96d46cc3839804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5076 Acc: 0.8203\n",
      "1639384797.8543744\n",
      "Epoch 24/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b306013b7ed346baa781a2cc2bd059a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4942 Acc: 0.8337\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86544c425c52400e9fbd95752184f99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4957 Acc: 0.8283\n",
      "1639384811.211729\n",
      "Epoch 25/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c3e8ae7abc4d78b170d92a00c0524c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4785 Acc: 0.8485\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606891cda41749f89ea4f5fc4e24b5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4842 Acc: 0.8413\n",
      "1639384824.973546\n",
      "Epoch 26/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479b52e70e384ebfa426cd67577e058c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4691 Acc: 0.8565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c8c92518384cbb9259fbdeb8bc011b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4755 Acc: 0.8471\n",
      "1639384838.8112617\n",
      "Epoch 27/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1392e47e7dcf4cd2ac36387b0ac0238a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4608 Acc: 0.8626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8335728f364f6dae863051e4137f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4709 Acc: 0.8529\n",
      "1639384852.978666\n",
      "Epoch 28/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4880b1654fe4a5c9b845f89ce1f16d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4546 Acc: 0.8670\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f563ac2f55ea48b9b4b01b2c3c70f487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4706 Acc: 0.8427\n",
      "Epoch 29/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3dd66f519645648c6da64973fa3614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4515 Acc: 0.8702\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8553d6ec8dde4e258fb0de29b3995ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4653 Acc: 0.8507\n",
      "Epoch 30/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40566e3324b4984a3bceb0826bc3a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4458 Acc: 0.8742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e1da2a5d9746e6a81245da2daf90ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4640 Acc: 0.8507\n",
      "Epoch 31/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc95214e64814f4b8169c96260b22b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4422 Acc: 0.8774\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49bd095f37634b3786cd97acbab2976d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4628 Acc: 0.8507\n",
      "Epoch 32/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7cceba9b92b4ee9b0f33085655f5bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4386 Acc: 0.8814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6e15f725e0466897475061f0220355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4556 Acc: 0.8601\n",
      "1639384918.7673357\n",
      "Epoch 33/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9621ba9fe740baa02eeac5d16c10c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4360 Acc: 0.8821\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9d4b0468f04175a5a78e5780c7ae84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4586 Acc: 0.8557\n",
      "Epoch 34/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56549aedfc294bedb002e396e4680703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4323 Acc: 0.8894\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5adadefaba3e4aa18e1048467415e326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4546 Acc: 0.8594\n",
      "Epoch 35/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b55e54953c64935986e1c8c8188613e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4304 Acc: 0.8890\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dbb733c7364c01a01bf2c9534fb419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4520 Acc: 0.8608\n",
      "1639384958.0610454\n",
      "Epoch 36/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a8b8e417ce4d1e9a6491f10881b131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4279 Acc: 0.8919\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f357248fa904459692e3182856e29da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4519 Acc: 0.8604\n",
      "Epoch 37/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527f08ddd9c94a0da48d1e1125333ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4263 Acc: 0.8930\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58081013184a47ccaa9e93dcfe4c13f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4485 Acc: 0.8641\n",
      "1639384986.4552097\n",
      "Epoch 38/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749f7b66ec7e4d2c8973fa650401e673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4245 Acc: 0.8933\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1fe2eefce0483eabf84d427c6cf3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4479 Acc: 0.8659\n",
      "1639385000.4497347\n",
      "Epoch 39/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bbd57934a44fc1b83c9818a58b2f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4229 Acc: 0.8962\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f4aad325f64a869ca2cfa2faf172b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4484 Acc: 0.8615\n",
      "Epoch 40/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f485404dc6db4b7c99bccf92da217ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4209 Acc: 0.8966\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f92751069c4560ac6fea4c6f8777f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4451 Acc: 0.8688\n",
      "1639385028.5957649\n",
      "Training complete in 8m 54s\n",
      "Best val Acc: 0.868764\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 40\n",
    "net = train_model(net, tfidf_dataloader_dict, criterion, optimizer, num_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fed10f",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509203c",
   "metadata": {},
   "source": [
    "#### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "5168e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datapath = 'Stage_2\\dataPublicComplete_s2\\dataPublicComplete'\n",
    "datapath = 'dataTrainComplete'\n",
    "txt_fnames = [splitext(f)[0] for f in listdir(datapath) if isfile(join(datapath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "f0406180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "df = pd.DataFrame([])\n",
    "for fname in txt_fnames:\n",
    "    txt = open(datapath+'/'+fname+'.txt', \"r\",encoding=\"utf-8\")\n",
    "    content = txt.read()\n",
    "    df = pd.concat([df, pd.Series([jieba.lcut(content, cut_all=False)])], axis = 0)\n",
    "df.columns = ['tokenization']\n",
    "df['name'] = txt_fnames\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "6b1aeb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping all the docs\n",
    "for index, row in df.iterrows():\n",
    "    row['tokenization'] = keyword_normalization(df.iloc[index]['tokenization'], vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "920393cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat tokenized text with space\n",
    "df2list = df.tokenization.tolist()\n",
    "cut_corpus = []\n",
    "for i in df2list:\n",
    "    cut_corpus.append(' '.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "6799fd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cut_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "6c2b0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing input\n",
    "# for CountVectorizer module to calculate the term frequency\n",
    "counts = count_vect.transform(cut_corpus).toarray()\n",
    "count_feature = count_vect.get_feature_names()\n",
    "# for TfidfVectorizer module to convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "tfidfs = tfidf_vect.transform(cut_corpus).toarray()\n",
    "tfidf_feature = tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "4c98076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_feature = np.array([])\n",
    "for i in np.arange(len(cut_corpus)):\n",
    "    if word2vec_feature.size == 0:\n",
    "        word2vec_feature = np.array([get_vector(cut_corpus[i])])\n",
    "    else:\n",
    "        # concat the two vectors by different columns\n",
    "        word2vec_feature = np.concatenate((word2vec_feature,np.array([get_vector(cut_corpus[i])])), axis = 0)\n",
    "# word2vec_feature.shape = (421, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2082fbe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1284/852056315.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# using these code as embedding features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform',\n\u001b[0m\u001b[0;32m      3\u001b[0m                        \u001b[0membeddings_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                        embeddings_constraint=None, mask_zero=False, input_length=None)\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex2vec\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# using these code as embedding features\n",
    "keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform',\n",
    "                       embeddings_regularizer=None, activity_regularizer=None,\n",
    "                       embeddings_constraint=None, mask_zero=False, input_length=None)\n",
    "model.add(Embedding(index2vec.shape[0], index2vec.shape[1], weights=[index2vec], trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "a6075a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "pair_list = []\n",
    "#Deprecated\n",
    "for fname1 in txt_fnames:\n",
    "    for fname2 in txt_fnames:\n",
    "        if(fname1 == fname2):continue\n",
    "        else:\n",
    "            labels[(fname1,fname2)] = 0\n",
    "            pair_list.append((fname1,fname2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "b3e94c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# decide which feature you want, tfidf or countvector or others\\ndef construct_test_input_vector(adapted_vector, tokenized_df, test_pair_list):\\n    input_vectors = np.array([])\\n    for i in np.arange(len(test_pair_list)):\\n        Test, Ref = test_pair_list[i] # order of docs\\n        Test_vec = adapted_vector[tokenized_df[tokenized_df['name']==Test].index[0]] # from order of doc to find out the order of vectors\\n        Ref_vec = adapted_vector[tokenized_df[tokenized_df['name']==Ref].index[0]] # same\\n        temp_vectors = np.concatenate(([Test_vec],[Ref_vec]), axis = 1) # concat the two vectors in same row\\n        if input_vectors.size == 0:\\n            input_vectors = temp_vectors\\n        else:\\n            input_vectors = np.concatenate((input_vectors,temp_vectors)) # concat the two vectors by different columns\\n    return input_vectors\\n\""
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# decide which feature you want, tfidf or countvector or others\n",
    "def construct_test_input_vector(adapted_vector, tokenized_df, test_pair_list):\n",
    "    input_vectors = np.array([])\n",
    "    for i in np.arange(len(test_pair_list)):\n",
    "        Test, Ref = test_pair_list[i] # order of docs\n",
    "        Test_vec = adapted_vector[tokenized_df[tokenized_df['name']==Test].index[0]] # from order of doc to find out the order of vectors\n",
    "        Ref_vec = adapted_vector[tokenized_df[tokenized_df['name']==Ref].index[0]] # same\n",
    "        temp_vectors = np.concatenate(([Test_vec],[Ref_vec]), axis = 1) # concat the two vectors in same row\n",
    "        if input_vectors.size == 0:\n",
    "            input_vectors = temp_vectors\n",
    "        else:\n",
    "            input_vectors = np.concatenate((input_vectors,temp_vectors)) # concat the two vectors by different columns\n",
    "    return input_vectors\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "a5ea7751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = construct_test_input_vector(tfidfs, df, pair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "c1b700e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560\n",
      "560\n",
      "560\n"
     ]
    }
   ],
   "source": [
    "tfidf_test_dict = {}\n",
    "for idx,vec in enumerate(tfidfs):\n",
    "    tfidf_test_dict[df.iloc[idx]['name']] = vec\n",
    "print(len(tfidf_test_dict))\n",
    "w2v_test_dict = {}\n",
    "for idx,vec in enumerate(word2vec_feature):\n",
    "    w2v_test_dict[df.iloc[idx]['name']] = vec\n",
    "print(len(w2v_dict))\n",
    "counts_dict = {}\n",
    "for idx,vec in enumerate(counts):\n",
    "    counts_dict[df.iloc[idx]['name']] = vec\n",
    "print(len(counts_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "5b10b116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99eeb70406954700b9474c7986291055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = []\n",
    "with torch.no_grad():\n",
    "    for test,ref in tqdm(pair_list):\n",
    "        input_vec = torch.tensor(np.concatenate((counts_dict[test], counts_dict[ref]), axis=None))\n",
    "        input_vec = input_vec.type(torch.FloatTensor).to(device)\n",
    "        lbl = net(input_vec)\n",
    "        out.append([(test,ref),lbl.cpu()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "673978a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[('1', '10'), tensor([9.9908e-01, 9.1622e-04])],\n",
       "  [('1', '1000'), tensor([0.9985, 0.0015])],\n",
       "  [('1', '1005'), tensor([0.9989, 0.0011])],\n",
       "  [('1', '1007'), tensor([9.9993e-01, 7.0890e-05])],\n",
       "  [('1', '1010'), tensor([0.9854, 0.0146])],\n",
       "  [('1', '1011'), tensor([9.9958e-01, 4.1698e-04])],\n",
       "  [('1', '1015'), tensor([9.9986e-01, 1.3595e-04])],\n",
       "  [('1', '1016'), tensor([0.9853, 0.0147])],\n",
       "  [('1', '1023'), tensor([0.9960, 0.0040])],\n",
       "  [('1', '1025'), tensor([0.8974, 0.1026])]],\n",
       " 242581)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "127c3e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1201 313040\n"
     ]
    }
   ],
   "source": [
    "better = []\n",
    "for o in out:\n",
    "    if(o[1][1] > 0.999999):better.append(o[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "ea1524a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292 1201\n",
      "Recall: 0.2111352133044107 Precision: 0.24313072439633637 F1 0.2260061919504644\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "bads = []\n",
    "for o in better:\n",
    "    if(o in pos_labels):count+=1\n",
    "    else:bads.append(o)\n",
    "recall,precision = count/len(pos_labels),count/len(better)\n",
    "print(count,len(better))\n",
    "print('Recall:',recall,'Precision:',precision,'F1',2*(recall*precision)/(recall+precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefac875",
   "metadata": {},
   "source": [
    "#### classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621427c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "5a9b014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "print(len(better))\n",
    "with open('val_w2v.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow([\"Test\"]+[\"Reference\"])\n",
    "    for row in better:  \n",
    "        spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d72ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
