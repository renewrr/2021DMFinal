{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ebc1624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67cd8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join,splitext\n",
    "t_dir = 'dataTrainComplete'\n",
    "txt_fnames = [splitext(f)[0] for f in listdir(t_dir) if isfile(join(t_dir, f))] #Article filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6bf5376",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_list = open('Keywords/02crop.list.csv', \"r\",encoding='UTF-8-sig')\n",
    "crop = crop_list.read()\n",
    "crop_line_sep = crop.splitlines()\n",
    "\n",
    "pest_list = open('Keywords/02pest.list.csv', \"r\",encoding='UTF-8-sig')\n",
    "pest = pest_list.read()\n",
    "pest_line_sep = pest.splitlines()\n",
    "\n",
    "chem_list = open('Keywords/02chem.list.csv', \"r\",encoding='UTF-8-sig')\n",
    "chem = chem_list.read()\n",
    "chem_line_sep = chem.splitlines()\n",
    "#Keywords split by lines, keyword with more than one entry will be on the same line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec20f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Renewrr\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.576 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import csv\n",
    "vector_dict = {}\n",
    "word_list = []\n",
    "#Keyword lookup with keyword as key and vector index as value\n",
    "for idx,line in enumerate(chain(crop_line_sep,pest_line_sep,chem_line_sep)):\n",
    "    l = line.split(',')\n",
    "    for word in l:\n",
    "        #Some line will have more than one entry, which should have the same vector index\n",
    "        if(word == ''):continue\n",
    "        jieba.add_word(word) #Each keyword is added to jieba\n",
    "        vector_dict[word] = l[0] # same meaning of different word will have same key number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e36b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding user dictionary\n",
    "userdict = ['多變', '溫差', '防檢局', '果農', '防範', '颱風', '台中市', '臺中市',\n",
    "            '發布', '發佈', '復育', '轄區', '臺南區', '開花期', '莫拉克', '桃園市', '新竹縣']\n",
    "for word in userdict:\n",
    "    jieba.add_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "553c903a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenization\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([])\n",
    "for fname in txt_fnames:\n",
    "    txt = open(t_dir+'/'+fname+'.txt', \"r\",encoding=\"utf-8\")\n",
    "    content = txt.read()\n",
    "    df = pd.concat([df, pd.Series([jieba.lcut(content, cut_all=False)])], axis = 0)\n",
    "df.columns = ['tokenization']\n",
    "df['name'] = txt_fnames\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9c6960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[梅雨季, 來臨, ，, 文旦, 黑點病, 易, 發生, ，, 請, 注意, 病徵, ，, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[天氣, 多變, 溫差, 大, ，, 近山區, 及, 偏施, 氮肥, 田區, 稻熱病, 發病...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[新聞稿, -, 稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, ...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, 防治, \\n, ...</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[乍暖, 還寒, ，, 防檢局, 籲請, 農友, 加強, 防治, 稻熱病, \\n, 農委會,...</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>[苗栗, 區農業, 改良, 場, 發佈, 水稻, 白葉枯病, 警報, \\n, 糧食, 作物,...</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>[雨, 後, 適合, 稻熱病, 發生, ，, 請持續, 進行, 監測, 並指導, 農民, 防...</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>[新, 入侵, 果實蠅, 緊急, 撲滅, 模擬, 演習,  ,  , 新聞稿, \\n, 新,...</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>[梨木蝨, 危害, ，, 請, 農友, 注意, 防範, \\n, 梨木蝨, 危害, ，, 請,...</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>[防範, 梨木蝨, 危害, ，, 請, 農友, 配合, 實施, 共同, 防治, \\n, 行政...</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tokenization  name\n",
       "0    [梅雨季, 來臨, ，, 文旦, 黑點病, 易, 發生, ，, 請, 注意, 病徵, ，, ...     1\n",
       "1    [天氣, 多變, 溫差, 大, ，, 近山區, 及, 偏施, 氮肥, 田區, 稻熱病, 發病...    10\n",
       "2    [新聞稿, -, 稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, ...  1000\n",
       "3    [稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, 防治, \\n, ...  1005\n",
       "4    [乍暖, 還寒, ，, 防檢局, 籲請, 農友, 加強, 防治, 稻熱病, \\n, 農委會,...  1007\n",
       "..                                                 ...   ...\n",
       "555  [苗栗, 區農業, 改良, 場, 發佈, 水稻, 白葉枯病, 警報, \\n, 糧食, 作物,...   986\n",
       "556  [雨, 後, 適合, 稻熱病, 發生, ，, 請持續, 進行, 監測, 並指導, 農民, 防...   988\n",
       "557  [新, 入侵, 果實蠅, 緊急, 撲滅, 模擬, 演習,  ,  , 新聞稿, \\n, 新,...   992\n",
       "558  [梨木蝨, 危害, ，, 請, 農友, 注意, 防範, \\n, 梨木蝨, 危害, ，, 請,...   997\n",
       "559  [防範, 梨木蝨, 危害, ，, 請, 農友, 配合, 實施, 共同, 防治, \\n, 行政...   998\n",
       "\n",
       "[560 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54f747a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the different word but have same meaning into one word\n",
    "def keyword_normalization(list_to_be_mapped, key_dict):\n",
    "    return [key_dict.get(a) if key_dict.get(a) else a for a in list_to_be_mapped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb2abb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping all the docs\n",
    "for index, row in df.iterrows():\n",
    "    row['tokenization'] = keyword_normalization(df.iloc[index]['tokenization'], vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0267950f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[梅雨季, 來臨, ，, 文旦柚, 黑點病, 易, 發生, ，, 請, 注意, 病徵, ，,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[天氣, 多變, 溫差, 大, ，, 近山區, 及, 偏施, 氮肥, 田區, 稻熱病, 發病...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[新聞稿, -, 稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, ...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, 防治, \\n, ...</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[乍暖, 還寒, ，, 防檢局, 籲請, 農友, 加強, 防治, 稻熱病, \\n, 農委會,...</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>[苗栗, 區農業, 改良, 場, 發佈, 水稻, 白葉枯病, 警報, \\n, 糧食, 作物,...</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>[雨, 後, 適合, 稻熱病, 發生, ，, 請持續, 進行, 監測, 並指導, 農民, 防...</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>[新, 入侵, 果實蠅, 緊急, 撲滅, 模擬, 演習, 三泰芬, 三泰芬, 新聞稿, \\n...</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>[梨木蝨, 危害, ，, 請, 農友, 注意, 防範, \\n, 梨木蝨, 危害, ，, 請,...</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>[防範, 梨木蝨, 危害, ，, 請, 農友, 配合, 實施, 共同, 防治, \\n, 行政...</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tokenization  name\n",
       "0    [梅雨季, 來臨, ，, 文旦柚, 黑點病, 易, 發生, ，, 請, 注意, 病徵, ，,...     1\n",
       "1    [天氣, 多變, 溫差, 大, ，, 近山區, 及, 偏施, 氮肥, 田區, 稻熱病, 發病...    10\n",
       "2    [新聞稿, -, 稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, ...  1000\n",
       "3    [稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, 防治, \\n, ...  1005\n",
       "4    [乍暖, 還寒, ，, 防檢局, 籲請, 農友, 加強, 防治, 稻熱病, \\n, 農委會,...  1007\n",
       "..                                                 ...   ...\n",
       "555  [苗栗, 區農業, 改良, 場, 發佈, 水稻, 白葉枯病, 警報, \\n, 糧食, 作物,...   986\n",
       "556  [雨, 後, 適合, 稻熱病, 發生, ，, 請持續, 進行, 監測, 並指導, 農民, 防...   988\n",
       "557  [新, 入侵, 果實蠅, 緊急, 撲滅, 模擬, 演習, 三泰芬, 三泰芬, 新聞稿, \\n...   992\n",
       "558  [梨木蝨, 危害, ，, 請, 農友, 注意, 防範, \\n, 梨木蝨, 危害, ，, 請,...   997\n",
       "559  [防範, 梨木蝨, 危害, ，, 請, 農友, 配合, 實施, 共同, 防治, \\n, 行政...   998\n",
       "\n",
       "[560 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "181f312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat tokenized text with space\n",
    "df2list = df.tokenization.tolist()\n",
    "cut_corpus = []\n",
    "for i in df2list:\n",
    "    cut_corpus.append(' '.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bde37a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cut_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c4a9bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'梅雨季 來臨 ， 文旦柚 黑點病 易 發生 ， 請 注意 病徵 ， 以及 早加強 防治 措施 。 \\n 5 月 已 進入 梅雨季 節 ， 近日 連續 降雨 ， 為 文旦柚 黑點病 開始 感染 的 時機 ， 往年 文旦柚 在 經過 4 - 6 月 的 春雨 及 梅雨季 後 ， 原來 長 得 亮麗 的 果實 外表 ， 會 開始 出現 許多 小黑 點 ， 現在 文旦柚 已 開始 進入 中果期 ， 花蓮區 農業 改良 場呼籲 應 注意 防治 。 \\n 除 冬季 清園 作業外 ， 在 4 - 8 月 時應 每月 施用 一次 56% 貝芬 硫 \\x7f 可濕性 粉劑 800 倍 、 或 22.7% \\x7f 硫 \\x7f 水懸劑 1000 倍 、 或 80% 鋅錳乃浦 500 倍 、 或 33% 鋅錳乃浦 500 倍 等 政府 核准 登記 使用 之藥劑 防治 ， 並依 登記 使用 方法 使用 ， 尤其 雨前 及雨後要 特別 加強 防治 ， 若遇 連續 降雨 時則 可 利用 間 歇 時 分區 進行 施藥 以 即 時 達 到 防治效果 。 \\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b8af794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# functions for analysis module\n",
    "\n",
    "# CountVector\n",
    "def CountVectorizer_model(data):\n",
    "    count_vect = CountVectorizer()\n",
    "    counts = count_vect.fit_transform(data).toarray() # type: np.array\n",
    "    # names per every features: count_vect.get_feature_names(), type: list\n",
    "    return count_vect, count_vect.get_feature_names(), counts\n",
    "\n",
    "# TF-IDF\n",
    "def TfidfVectorizer_model(data):\n",
    "    tfidf_vect = TfidfVectorizer()\n",
    "    tfidfs = tfidf_vect.fit_transform(data).toarray()\n",
    "    return tfidf_vect, tfidf_vect.get_feature_names(), tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5f73da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Renewrr\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# for CountVectorizer module to calculate the term frequency\n",
    "count_vect, count_feature, counts = CountVectorizer_model(cut_corpus)\n",
    "# for TfidfVectorizer module to convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "tfidf_vect, tfidf_feature, tfidfs = TfidfVectorizer_model(cut_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "2d31d239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "741ef1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10646"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "ca8864da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.12346158, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.09047349, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "cb46a12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '02',\n",
       " '03',\n",
       " '037',\n",
       " '039',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '069',\n",
       " '07',\n",
       " '08',\n",
       " '0800',\n",
       " '0800039131',\n",
       " '089',\n",
       " '090',\n",
       " '0905',\n",
       " '0932',\n",
       " '0935425837',\n",
       " '095',\n",
       " '0972',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10004',\n",
       " '1000x',\n",
       " '100g',\n",
       " '101',\n",
       " '103',\n",
       " '104',\n",
       " '105',\n",
       " '1051102',\n",
       " '106',\n",
       " '108',\n",
       " '109',\n",
       " '11',\n",
       " '110',\n",
       " '118',\n",
       " '12',\n",
       " '1200',\n",
       " '12000',\n",
       " '127',\n",
       " '13',\n",
       " '130',\n",
       " '1300',\n",
       " '131',\n",
       " '139',\n",
       " '14',\n",
       " '145',\n",
       " '146',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '154',\n",
       " '1542',\n",
       " '15mm',\n",
       " '16',\n",
       " '1600',\n",
       " '1684',\n",
       " '1686',\n",
       " '17',\n",
       " '1700',\n",
       " '17512',\n",
       " '1783',\n",
       " '18',\n",
       " '1800',\n",
       " '1845',\n",
       " '19',\n",
       " '192',\n",
       " '1990',\n",
       " '1mm',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2002',\n",
       " '2006',\n",
       " '20492',\n",
       " '205',\n",
       " '206',\n",
       " '20for',\n",
       " '20japan1021226',\n",
       " '21',\n",
       " '22',\n",
       " '222111',\n",
       " '224',\n",
       " '23',\n",
       " '23431471',\n",
       " '23431473',\n",
       " '236583',\n",
       " '236619',\n",
       " '24',\n",
       " '25',\n",
       " '250',\n",
       " '2500',\n",
       " '250g',\n",
       " '251',\n",
       " '256',\n",
       " '2566',\n",
       " '26',\n",
       " '260',\n",
       " '2665',\n",
       " '2679526',\n",
       " '268',\n",
       " '27',\n",
       " '272',\n",
       " '277',\n",
       " '28',\n",
       " '29',\n",
       " '2face',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30000',\n",
       " '301',\n",
       " '302',\n",
       " '303',\n",
       " '305',\n",
       " '306',\n",
       " '307',\n",
       " '308',\n",
       " '309',\n",
       " '31',\n",
       " '310',\n",
       " '311',\n",
       " '313',\n",
       " '315',\n",
       " '32',\n",
       " '320',\n",
       " '321',\n",
       " '322046',\n",
       " '323',\n",
       " '325015',\n",
       " '325110',\n",
       " '327',\n",
       " '327904',\n",
       " '33',\n",
       " '3307',\n",
       " '333mp',\n",
       " '34',\n",
       " '35',\n",
       " '350',\n",
       " '351',\n",
       " '358616',\n",
       " '358618',\n",
       " '36',\n",
       " '360',\n",
       " '3600',\n",
       " '361786',\n",
       " '3691ctnode',\n",
       " '37',\n",
       " '370',\n",
       " '3751574',\n",
       " '38',\n",
       " '382',\n",
       " '39',\n",
       " '390',\n",
       " '3mm',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '409',\n",
       " '41',\n",
       " '411',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '441',\n",
       " '443',\n",
       " '45',\n",
       " '450',\n",
       " '46',\n",
       " '460',\n",
       " '47',\n",
       " '476',\n",
       " '4768216',\n",
       " '48',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '500g',\n",
       " '52',\n",
       " '525g',\n",
       " '526',\n",
       " '53',\n",
       " '53715',\n",
       " '5371574',\n",
       " '54',\n",
       " '5400',\n",
       " '55',\n",
       " '552',\n",
       " '5523270',\n",
       " '5523307',\n",
       " '558124',\n",
       " '56',\n",
       " '58',\n",
       " '590',\n",
       " '5912901',\n",
       " '5912905',\n",
       " '5x10',\n",
       " '60',\n",
       " '600',\n",
       " '6000',\n",
       " '61',\n",
       " '613',\n",
       " '62',\n",
       " '63',\n",
       " '632',\n",
       " '634',\n",
       " '64',\n",
       " '65',\n",
       " '650',\n",
       " '6622274',\n",
       " '67',\n",
       " '68',\n",
       " '683',\n",
       " '70',\n",
       " '700',\n",
       " '700pcu',\n",
       " '71',\n",
       " '72',\n",
       " '72000',\n",
       " '7229461',\n",
       " '73',\n",
       " '730',\n",
       " '73000',\n",
       " '737',\n",
       " '738',\n",
       " '7389060',\n",
       " '7389158',\n",
       " '74',\n",
       " '744',\n",
       " '75',\n",
       " '750',\n",
       " '7500',\n",
       " '76',\n",
       " '7642',\n",
       " '7665',\n",
       " '7665page',\n",
       " '77',\n",
       " '7746728',\n",
       " '7746741',\n",
       " '7746755',\n",
       " '7746761',\n",
       " '78',\n",
       " '79',\n",
       " '7cfu',\n",
       " '7g',\n",
       " '80',\n",
       " '800',\n",
       " '8000',\n",
       " '81',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '850',\n",
       " '8521108',\n",
       " '8521114',\n",
       " '8521493',\n",
       " '8535915',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '880',\n",
       " '89',\n",
       " '90',\n",
       " '900',\n",
       " '901',\n",
       " '9030',\n",
       " '9031',\n",
       " '9060',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '9632',\n",
       " '97',\n",
       " '977',\n",
       " '98',\n",
       " '9899739',\n",
       " '99',\n",
       " '9cfu',\n",
       " 'acerialitchi',\n",
       " 'ageratumyellowveinvirus',\n",
       " 'agral',\n",
       " 'annonasquamosa',\n",
       " 'anonaepestisbengalella',\n",
       " 'aphiq',\n",
       " 'app',\n",
       " 'articles',\n",
       " 'aspx',\n",
       " 'ayvv',\n",
       " 'banana',\n",
       " 'baphig',\n",
       " 'baphiq',\n",
       " 'blackrotofpapaya',\n",
       " 'c3',\n",
       " 'catid',\n",
       " 'cmv',\n",
       " 'coa',\n",
       " 'cs',\n",
       " 'ct',\n",
       " 'cucumbermosaicvirus',\n",
       " 'drug',\n",
       " 'dug',\n",
       " 'faw',\n",
       " 'file',\n",
       " 'filelink1fontsize',\n",
       " 'fontdivid',\n",
       " 'formmap',\n",
       " 'fp2000',\n",
       " 'fusariummangiferae',\n",
       " 'g1',\n",
       " 'googlemap',\n",
       " 'gov',\n",
       " 'hdais',\n",
       " 'hdares',\n",
       " 'htdocs',\n",
       " 'htm',\n",
       " 'htmlarea',\n",
       " 'http',\n",
       " 'https',\n",
       " 'id',\n",
       " 'index',\n",
       " 'insecticides',\n",
       " 'kdais',\n",
       " 'keifer',\n",
       " 'line',\n",
       " 'linfa',\n",
       " 'list',\n",
       " 'longanwitchsbroom',\n",
       " 'longwang',\n",
       " 'mango',\n",
       " 'mango1020812',\n",
       " 'mdaes',\n",
       " 'mdais',\n",
       " 'menuitem1',\n",
       " 'menuitem5',\n",
       " 'meskell',\n",
       " 'mm',\n",
       " 'news',\n",
       " 'newsdetailviews',\n",
       " 'nsf',\n",
       " 'openform',\n",
       " 'org',\n",
       " 'otserv2',\n",
       " 'pdf',\n",
       " 'pe',\n",
       " 'peronophythoralitchii',\n",
       " 'pess',\n",
       " 'pesticide',\n",
       " 'ph6',\n",
       " 'philusantennatus',\n",
       " 'phis',\n",
       " 'php',\n",
       " 'phyllotretastriolata',\n",
       " 'phytoplasma',\n",
       " 'planococcusminor',\n",
       " 'plant',\n",
       " 'porbenazole',\n",
       " 'potatovirusy',\n",
       " 'potect',\n",
       " 'ppm',\n",
       " 'ppmtable',\n",
       " 'ppmtale',\n",
       " 'prevention',\n",
       " 'protect',\n",
       " 'pseudomonassyringae',\n",
       " 'pvy',\n",
       " 'pythium',\n",
       " 'pythiumspp',\n",
       " 'rhizoctonia',\n",
       " 'rhizoctoniasolani',\n",
       " 'riced',\n",
       " 'rid',\n",
       " 'scirtothripsdorsalis',\n",
       " 'sn',\n",
       " 'streptomycin',\n",
       " 'sug',\n",
       " 'tacti',\n",
       " 'tactri',\n",
       " 'tdais',\n",
       " 'tecloftalam',\n",
       " 'tetracycline',\n",
       " 'theme',\n",
       " 'tndais',\n",
       " 'tomatomosaicvirus',\n",
       " 'tomatospottedwiltvirus',\n",
       " 'tomatoyellowleafcurlvirus',\n",
       " 'tomv',\n",
       " 'tswv',\n",
       " 'tw',\n",
       " 'tylcv',\n",
       " 'vesicatoria',\n",
       " 'view',\n",
       " 'we',\n",
       " 'web',\n",
       " 'webevery',\n",
       " 'wp1500',\n",
       " 'ws',\n",
       " 'wsite',\n",
       " 'www',\n",
       " 'xanthomonascampestrispv',\n",
       " 'xitem',\n",
       " '一久',\n",
       " '一二',\n",
       " '一五',\n",
       " '一些',\n",
       " '一個',\n",
       " '一個蟲',\n",
       " '一傳真',\n",
       " '一傷口',\n",
       " '一公頃',\n",
       " '一六號',\n",
       " '一分',\n",
       " '一則',\n",
       " '一千一百',\n",
       " '一千零五',\n",
       " '一半',\n",
       " '一圈',\n",
       " '一堆',\n",
       " '一大',\n",
       " '一天',\n",
       " '一季',\n",
       " '一定',\n",
       " '一害蟲',\n",
       " '一小',\n",
       " '一層',\n",
       " '一帶',\n",
       " '一年',\n",
       " '一幼葉',\n",
       " '一排',\n",
       " '一斑',\n",
       " '一日',\n",
       " '一旦',\n",
       " '一時',\n",
       " '一期',\n",
       " '一期稻作',\n",
       " '一果',\n",
       " '一株',\n",
       " '一條',\n",
       " '一次',\n",
       " '一步',\n",
       " '一段',\n",
       " '一波',\n",
       " '一波接',\n",
       " '一波鋒面',\n",
       " '一片',\n",
       " '一生',\n",
       " '一百',\n",
       " '一百五十',\n",
       " '一直',\n",
       " '一種',\n",
       " '一級',\n",
       " '一致',\n",
       " '一般',\n",
       " '一般而言',\n",
       " '一蟲',\n",
       " '一行',\n",
       " '一賃',\n",
       " '一起',\n",
       " '一路',\n",
       " '一輪',\n",
       " '一連',\n",
       " '一週',\n",
       " '一邊',\n",
       " '一鉀',\n",
       " '一鐵樹',\n",
       " '一陣',\n",
       " '一面',\n",
       " '一項',\n",
       " '一點',\n",
       " '一齡',\n",
       " '丁基加保扶',\n",
       " '七五',\n",
       " '七分',\n",
       " '七天',\n",
       " '七年',\n",
       " '七張',\n",
       " '七日',\n",
       " '七月',\n",
       " '七股',\n",
       " '七至',\n",
       " '七路',\n",
       " '三一',\n",
       " '三個',\n",
       " '三元',\n",
       " '三元硫酸銅',\n",
       " '三到',\n",
       " '三則',\n",
       " '三化螟',\n",
       " '三十',\n",
       " '三十五',\n",
       " '三十度',\n",
       " '三十日',\n",
       " '三千',\n",
       " '三四',\n",
       " '三塞唑',\n",
       " '三大',\n",
       " '三層',\n",
       " '三得芬',\n",
       " '三星',\n",
       " '三月',\n",
       " '三次',\n",
       " '三民',\n",
       " '三氟敏',\n",
       " '三氟派瑞',\n",
       " '三氯松',\n",
       " '三泰芬',\n",
       " '三泰隆',\n",
       " '三灣',\n",
       " '三片',\n",
       " '三種',\n",
       " '三縣',\n",
       " '三至',\n",
       " '三處',\n",
       " '三要素',\n",
       " '三變',\n",
       " '三賽唑',\n",
       " '三路',\n",
       " '三週',\n",
       " '三項',\n",
       " '三齡',\n",
       " '上下',\n",
       " '上並',\n",
       " '上之病',\n",
       " '上令',\n",
       " '上以',\n",
       " '上位',\n",
       " '上傳',\n",
       " '上出',\n",
       " '上列',\n",
       " '上則',\n",
       " '上化',\n",
       " '上升',\n",
       " '上午',\n",
       " '上及',\n",
       " '上噴',\n",
       " '上均',\n",
       " '上市',\n",
       " '上常',\n",
       " '上應',\n",
       " '上方',\n",
       " '上旬',\n",
       " '上會出',\n",
       " '上會產生',\n",
       " '上產卵',\n",
       " '上產生',\n",
       " '上病',\n",
       " '上移',\n",
       " '上端',\n",
       " '上策',\n",
       " '上經',\n",
       " '上維持',\n",
       " '上網',\n",
       " '上要',\n",
       " '上覆',\n",
       " '上轉',\n",
       " '上述',\n",
       " '上部',\n",
       " '上除',\n",
       " '上須',\n",
       " '上黃化',\n",
       " '下一代',\n",
       " '下位',\n",
       " '下供',\n",
       " '下列',\n",
       " '下午',\n",
       " '下半年',\n",
       " '下均',\n",
       " '下垂',\n",
       " '下將',\n",
       " '下山',\n",
       " '下己',\n",
       " '下播種',\n",
       " '下方',\n",
       " '下旬',\n",
       " '下易',\n",
       " '下易產生',\n",
       " '下會',\n",
       " '下會產生',\n",
       " '下期',\n",
       " '下極',\n",
       " '下次',\n",
       " '下產生',\n",
       " '下田',\n",
       " '下端',\n",
       " '下葉鞘',\n",
       " '下藥',\n",
       " '下表',\n",
       " '下表中',\n",
       " '下載',\n",
       " '下述',\n",
       " '下部',\n",
       " '下開',\n",
       " '下降',\n",
       " '下陷',\n",
       " '下雨',\n",
       " '下面',\n",
       " '不下',\n",
       " '不久',\n",
       " '不予',\n",
       " '不二',\n",
       " '不但',\n",
       " '不佳',\n",
       " '不佳及',\n",
       " '不佳時',\n",
       " '不來',\n",
       " '不僅',\n",
       " '不像',\n",
       " '不償失',\n",
       " '不全',\n",
       " '不具',\n",
       " '不再',\n",
       " '不利',\n",
       " '不到',\n",
       " '不勾頭',\n",
       " '不及',\n",
       " '不可',\n",
       " '不同',\n",
       " '不善',\n",
       " '不堪',\n",
       " '不外乎',\n",
       " '不大',\n",
       " '不如',\n",
       " '不定',\n",
       " '不宜',\n",
       " '不容',\n",
       " '不少',\n",
       " '不展',\n",
       " '不常見',\n",
       " '不建議',\n",
       " '不得',\n",
       " '不必',\n",
       " '不慎',\n",
       " '不應',\n",
       " '不持續',\n",
       " '不整',\n",
       " '不斷',\n",
       " '不明',\n",
       " '不易',\n",
       " '不是',\n",
       " '不時',\n",
       " '不會',\n",
       " '不會產生',\n",
       " '不會重',\n",
       " '不正',\n",
       " '不用',\n",
       " '不當',\n",
       " '不盡',\n",
       " '不稔',\n",
       " '不管',\n",
       " '不絕',\n",
       " '不織布',\n",
       " '不能',\n",
       " '不致',\n",
       " '不良',\n",
       " '不著果',\n",
       " '不表現',\n",
       " '不要',\n",
       " '不見',\n",
       " '不規則',\n",
       " '不論',\n",
       " '不論行',\n",
       " '不足',\n",
       " '不通',\n",
       " '不過',\n",
       " '不過量',\n",
       " '不遠',\n",
       " '不錯',\n",
       " '不間',\n",
       " '不飛翔',\n",
       " '不飽滿',\n",
       " '不高',\n",
       " '且僅',\n",
       " '且務必',\n",
       " '且慢',\n",
       " '且施',\n",
       " '且易',\n",
       " '且易降',\n",
       " '且晨間',\n",
       " '且會',\n",
       " '且果',\n",
       " '且現',\n",
       " '且逢蕉株',\n",
       " '且須',\n",
       " '世代',\n",
       " '世界',\n",
       " '世界性',\n",
       " '世紀',\n",
       " '丙基喜樂松',\n",
       " '丟棄',\n",
       " '並上',\n",
       " '並不',\n",
       " '並不發生',\n",
       " '並不顯',\n",
       " '並且',\n",
       " '並仔細',\n",
       " '並仔細將',\n",
       " '並以',\n",
       " '並使',\n",
       " '並依',\n",
       " '並依其',\n",
       " '並依據',\n",
       " '並保護',\n",
       " '並保護天',\n",
       " '並傳',\n",
       " '並傳播',\n",
       " '並出',\n",
       " '並出現',\n",
       " '並分次',\n",
       " '並加',\n",
       " '並加強',\n",
       " '並勇',\n",
       " '並務',\n",
       " '並務必',\n",
       " '並勿',\n",
       " '並參考',\n",
       " '並及',\n",
       " '並可',\n",
       " '並可作',\n",
       " '並同時',\n",
       " '並向',\n",
       " '並向果',\n",
       " '並呈萎',\n",
       " '並噴施',\n",
       " '並嚴',\n",
       " '並嚴格',\n",
       " '並因',\n",
       " '並在',\n",
       " '並在種',\n",
       " '並在終',\n",
       " '並均勻',\n",
       " '並增',\n",
       " '並委由清',\n",
       " '並宜',\n",
       " '並將',\n",
       " '並將果',\n",
       " '並將藥',\n",
       " '並已',\n",
       " '並常圍',\n",
       " '並常腫',\n",
       " '並建議',\n",
       " '並影響',\n",
       " '並從病',\n",
       " '並徹底',\n",
       " '並應',\n",
       " '並應加',\n",
       " '並應用',\n",
       " '並懸掛',\n",
       " '並持續',\n",
       " '並指導',\n",
       " '並採',\n",
       " '並採取',\n",
       " '並散',\n",
       " '並於一',\n",
       " '並於主幹',\n",
       " '並於後續',\n",
       " '並於採',\n",
       " '並於施藥',\n",
       " '並於果',\n",
       " '並於田間',\n",
       " '並於終',\n",
       " '並於開',\n",
       " '並曝曬',\n",
       " '並曾',\n",
       " '並會',\n",
       " '並會長',\n",
       " '並有',\n",
       " '並未',\n",
       " '並每',\n",
       " '並決定',\n",
       " '並流膠',\n",
       " '並減',\n",
       " '並潛伏',\n",
       " '並無',\n",
       " '並無抗',\n",
       " '並無攜',\n",
       " '並無黃色',\n",
       " '並燒',\n",
       " '並特別',\n",
       " '並產',\n",
       " '並產卵',\n",
       " '並產生',\n",
       " '並盡量',\n",
       " '並確',\n",
       " '並確切',\n",
       " '並確實',\n",
       " '並立',\n",
       " '並給予',\n",
       " '並聯合',\n",
       " '並自',\n",
       " '並與',\n",
       " '並與縣',\n",
       " '並行',\n",
       " '並補施',\n",
       " '並補植',\n",
       " '並褐化',\n",
       " '並視',\n",
       " '並請',\n",
       " '並請務必',\n",
       " '並輪流',\n",
       " '並輪用',\n",
       " '並轉',\n",
       " '並逐漸',\n",
       " '並通報',\n",
       " '並進',\n",
       " '並進入',\n",
       " '並進行',\n",
       " '並達',\n",
       " '並適',\n",
       " '並適法',\n",
       " '並適當',\n",
       " '並適量',\n",
       " '並選',\n",
       " '並選擇',\n",
       " '並選用',\n",
       " '並選留',\n",
       " '並避開',\n",
       " '並酌',\n",
       " '並針',\n",
       " '並長',\n",
       " '並關閉',\n",
       " '並隨即',\n",
       " '並隨時',\n",
       " '並隨葉脈',\n",
       " '並需',\n",
       " '並非',\n",
       " '並食',\n",
       " '並鼓勵',\n",
       " '中下旬',\n",
       " '中之卵',\n",
       " '中之果',\n",
       " '中之落',\n",
       " '中以',\n",
       " '中任',\n",
       " '中作',\n",
       " '中供',\n",
       " '中化',\n",
       " '中北部',\n",
       " '中區',\n",
       " '中午',\n",
       " '中南部',\n",
       " '中及',\n",
       " '中和液',\n",
       " '中噴藥',\n",
       " '中埔',\n",
       " '中場',\n",
       " '中場籲',\n",
       " '中大果期',\n",
       " '中央',\n",
       " '中始',\n",
       " '中小',\n",
       " '中常',\n",
       " '中度',\n",
       " '中往',\n",
       " '中後期',\n",
       " '中心',\n",
       " '中所',\n",
       " '中抗',\n",
       " '中旬',\n",
       " '中是',\n",
       " '中期',\n",
       " '中果',\n",
       " '中果期',\n",
       " '中株',\n",
       " '中株期',\n",
       " '中殘留',\n",
       " '中段',\n",
       " '中毒',\n",
       " '中水',\n",
       " '中產卵',\n",
       " '中秋',\n",
       " '中等',\n",
       " '中籲',\n",
       " '中結',\n",
       " '中縣',\n",
       " '中脈',\n",
       " '中華民國',\n",
       " '中蕉',\n",
       " '中該',\n",
       " '中誘',\n",
       " '中農',\n",
       " '中達',\n",
       " '中部',\n",
       " '中針',\n",
       " '中間',\n",
       " '中闊',\n",
       " '中髓',\n",
       " '串飽度',\n",
       " '主動',\n",
       " '主因',\n",
       " '主幹',\n",
       " '主幹樹',\n",
       " '主持人',\n",
       " '主梗穗',\n",
       " '主產區',\n",
       " '主管',\n",
       " '主脈',\n",
       " '主要',\n",
       " '主辦',\n",
       " '乃力松',\n",
       " '乃是',\n",
       " '乃為',\n",
       " '久旱',\n",
       " '久旱不雨',\n",
       " '之一',\n",
       " '之下',\n",
       " '之中',\n",
       " '之久',\n",
       " '之以',\n",
       " '之依據',\n",
       " '之側',\n",
       " '之傳播',\n",
       " '之傳染',\n",
       " '之前',\n",
       " '之劑',\n",
       " '之務為',\n",
       " '之區域',\n",
       " '之協助',\n",
       " '之卵',\n",
       " '之卵粒',\n",
       " '之品',\n",
       " '之品種',\n",
       " '之品質',\n",
       " '之園區',\n",
       " '之圓圈',\n",
       " '之圓形',\n",
       " '之土',\n",
       " '之報',\n",
       " '之場',\n",
       " '之夏',\n",
       " '之夏蕉',\n",
       " '之外',\n",
       " '之大',\n",
       " '之天',\n",
       " '之好',\n",
       " '之季節',\n",
       " '之害蟲',\n",
       " '之小果',\n",
       " '之小點',\n",
       " '之展',\n",
       " '之山區',\n",
       " '之帶',\n",
       " '之幼蟲',\n",
       " '之後再',\n",
       " '之後擴',\n",
       " '之後轉',\n",
       " '之感病',\n",
       " '之成',\n",
       " '之成敗',\n",
       " '之成蟲',\n",
       " '之效',\n",
       " '之明',\n",
       " '之明顯',\n",
       " '之時',\n",
       " '之時期',\n",
       " '之時間',\n",
       " '之有',\n",
       " '之木',\n",
       " '之果',\n",
       " '之果園',\n",
       " '之果實',\n",
       " '之枝條',\n",
       " '之根際',\n",
       " '之桃園',\n",
       " '之梨穗',\n",
       " '之毒',\n",
       " '之氣候',\n",
       " '之氣溫',\n",
       " '之災害',\n",
       " '之為害',\n",
       " '之環境',\n",
       " '之生',\n",
       " '之生長',\n",
       " '之產生',\n",
       " '之產量',\n",
       " '之用',\n",
       " '之田區',\n",
       " '之田區須',\n",
       " '之田園',\n",
       " '之田間',\n",
       " '之病',\n",
       " '之登',\n",
       " '之登記',\n",
       " '之發',\n",
       " '之省',\n",
       " '之秧',\n",
       " '之稀釋',\n",
       " '之稔',\n",
       " '之種',\n",
       " '之稻',\n",
       " '之粒劑',\n",
       " '之系',\n",
       " '之細菌性',\n",
       " '之細長',\n",
       " '之經濟',\n",
       " '之緊',\n",
       " '之花穗',\n",
       " ...]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebe26f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from scipy import spatial\n",
    "## setting\n",
    "vector_dim = 200\n",
    "window_size = 5\n",
    "min_count = 1\n",
    "training_iter = 20\n",
    "\n",
    "## model\n",
    "word2vec_model = Word2Vec(sentences=df2list,\n",
    "                          vector_size=vector_dim, window=window_size, \n",
    "                          min_count=min_count, epochs=training_iter)\n",
    "# index to word\n",
    "index_to_word = word2vec_model.wv.index_to_key  # len(word2vec_model.wv.index2word) = 8659\n",
    "# index to vectors\n",
    "index2vec = word2vec_model.wv.vectors # word2vec_model.wv.vectors.shape = (8659, 100)\n",
    "\n",
    "def preprocess(s):\n",
    "    return [i.lower() for i in s.split()]\n",
    "def get_vector(s):\n",
    "    for i in preprocess(s):\n",
    "        try:\n",
    "            values = np.sum(np.array([word2vec_model.wv[i]]), axis=0)#Change\n",
    "        except KeyError:\n",
    "            c = 0\n",
    "    return values\n",
    "\n",
    "word2vec_feature = np.array([])\n",
    "for i in np.arange(len(cut_corpus)):\n",
    "    if word2vec_feature.size == 0:\n",
    "        word2vec_feature = np.array([get_vector(cut_corpus[i])])\n",
    "    else:\n",
    "        # concat the two vectors by different columns\n",
    "        word2vec_feature = np.concatenate((word2vec_feature,np.array([get_vector(cut_corpus[i])])), axis = 0)\n",
    "\n",
    "# word2vec_feature.shape = (560, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "819e8a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313040\n",
      "1383\n",
      "313040\n"
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "pair_list = []\n",
    "#Deprecated\n",
    "for fname1 in txt_fnames:\n",
    "    for fname2 in txt_fnames:\n",
    "        if(fname1 == fname2):continue\n",
    "        else:\n",
    "            labels[(fname1,fname2)] = 0\n",
    "            pair_list.append((fname1,fname2))\n",
    "corr_list = open('TrainLabel.csv', \"r\",encoding='UTF-8-sig')\n",
    "corr = corr_list.read()\n",
    "corr_line_sep = corr.splitlines()\n",
    "#Training label\n",
    "for line in corr_line_sep[1:]:\n",
    "    l = line.split(',')\n",
    "    labels[(l[0],l[1])] = 1\n",
    "print(len(labels))\n",
    "print(sum(labels.values()))\n",
    "print(len(pair_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95a21fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313040\n"
     ]
    }
   ],
   "source": [
    "pos_pair_list = []\n",
    "pos_labels = set() #faster lookup to filter out positive pairs, not used elsewhere\n",
    "#All the associated article pairs given by train label\n",
    "for line in corr_line_sep[1:]:\n",
    "    l = line.split(',')\n",
    "    pos_pair_list.append((l[0],l[1]))\n",
    "    pos_labels.add((l[0],l[1]))\n",
    "neg_pair_list = []\n",
    "#Other pairs with no association\n",
    "for fname1 in txt_fnames:\n",
    "    for fname2 in txt_fnames:\n",
    "        if(fname1 == fname2):continue\n",
    "        if((fname1,fname2) not in pos_labels): #Filter out positive pairs\n",
    "            neg_pair_list.append((fname1,fname2))\n",
    "print(len(pos_pair_list)+len(neg_pair_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d43ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# decide which feature you want, tfidf or countvector or others\n",
    "def construct_input_vector(adapted_vector, tokenized_df, pos_pair_list, neg_pair_list):\n",
    "    pl = len(pos_pair_list) # Number of positive pairs\n",
    "    neg_keys = random.sample(neg_pair_list,pl) # same length of negative pairs\n",
    "    sample_labels = {}\n",
    "    for key in neg_keys:sample_labels[key] = 0\n",
    "    for key in pos_pair_list:sample_labels[key] = 1\n",
    "    sample_pair_list = pos_pair_list + neg_keys\n",
    "    sample_labels_list = []\n",
    "    input_vectors = np.array([])\n",
    "    for i in np.arange(len(sample_pair_list)):\n",
    "        Test, Ref = sample_pair_list[i] # order of docs\n",
    "        sample_labels_list.append(sample_labels[(Test,Ref)]) # labels\n",
    "        Test_vec = adapted_vector[tokenized_df[tokenized_df['name']==Test].index[0]] # from order of doc to find out the order of vectors\n",
    "        Ref_vec = adapted_vector[tokenized_df[tokenized_df['name']==Ref].index[0]] # same\n",
    "        temp_vectors = np.concatenate(([Test_vec],[Ref_vec]), axis = 1) # concat the two vectors in same row\n",
    "        if input_vectors.size == 0:\n",
    "            input_vectors = temp_vectors\n",
    "        else:\n",
    "            input_vectors = np.concatenate((input_vectors,temp_vectors)) # concat the two vectors by different columns\n",
    "    return input_vectors, sample_labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75664f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vectors0, sample_labels_list0 = construct_input_vector(tfidfs, df, pos_pair_list, neg_pair_list)\n",
    "# input_vectors0.shape, len(sample_labels_list0) = (2766, 15122), 2766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0901bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vectors1, sample_labels_list1 = construct_input_vector(counts, df, pos_pair_list, neg_pair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "146af23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vectors2, sample_labels_list2 = construct_input_vector(word2vec_feature, df, pos_pair_list, neg_pair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97d54cdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1284/852056315.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# using these code as embedding features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform',\n\u001b[0m\u001b[0;32m      3\u001b[0m                        \u001b[0membeddings_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                        embeddings_constraint=None, mask_zero=False, input_length=None)\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex2vec\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# using these code as embedding features\n",
    "keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform',\n",
    "                       embeddings_regularizer=None, activity_regularizer=None,\n",
    "                       embeddings_constraint=None, mask_zero=False, input_length=None)\n",
    "model.add(Embedding(index2vec.shape[0], index2vec.shape[1], weights=[index2vec], trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "fd1915ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 10646)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vectors0.shape,input_vectors1.shape,input_vectors2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a70b1",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "c0aee5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560\n"
     ]
    }
   ],
   "source": [
    "#df.iloc[0]['name']\n",
    "#tfidf_dict = {}\n",
    "#for idx,vec in enumerate(tfidfs):\n",
    "    #tfidf_dict[df.iloc[idx]['name']] = vec\n",
    "#print(len(tfidf_dict))\n",
    "#w2v_dict = {}\n",
    "#for idx,vec in enumerate(word2vec_feature):\n",
    "    #w2v_dict[df.iloc[idx]['name']] = vec\n",
    "#print(len(w2v_dict))\n",
    "counts_dict = {}\n",
    "for idx,vec in enumerate(counts):\n",
    "    counts_dict[df.iloc[idx]['name']] = vec\n",
    "print(len(counts_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8d908b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "# Dataset\n",
    "#Custom dataset, currently generates a 50/50 split of positive and negative sample\n",
    "#To change the split, change the second variable of random.sample and the __len__ function accordingly\n",
    "class PartDataset(data.Dataset):\n",
    "    def __init__(self, pos_pair_list, neg_pair_list, vectors):\n",
    "        self.l = len(pos_pair_list)#Number of positive pairs\n",
    "        neg_keys = random.sample(neg_pair_list,self.l)#Sample negative pairs, change the second variable to change the split\n",
    "        self.labels = {}\n",
    "        for key in neg_keys:self.labels[key] = 0\n",
    "        for key in pos_pair_list:self.labels[key] = 1\n",
    "        self.pair_list = pos_pair_list+neg_keys\n",
    "        self.vectors = vectors\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.l*2\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        Test,Ref = self.pair_list[idx]\n",
    "        label = self.labels[(Test,Ref)]\n",
    "        #comb_vector = self.vectors[Test] + self.vectors[Ref]\n",
    "        comb_vector = np.concatenate((self.vectors[Test], self.vectors[Ref]), axis=None)\n",
    "        return torch.tensor(comb_vector), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f2fd099",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdim_tfidf = len(tfidfs[0])\n",
    "class TfIdfNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TfIdfNeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(inputdim_tfidf*2, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 56),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(56, 2),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "inputdim_w2v = len(word2vec_feature[0])\n",
    "class w2vNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(w2vNeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(inputdim_w2v*2, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(50, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(20, 2),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "06b24d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = PartDataset(pos_pair_list, neg_pair_list, tfidf_dict)\n",
    "#test_dataset = PartDataset(pos_pair_list, neg_pair_list, tfidf_dict)\n",
    "#train_dataset = PartDataset(pos_pair_list, neg_pair_list, w2v_dict)\n",
    "#test_dataset = PartDataset(pos_pair_list, neg_pair_list, w2v_dict)\n",
    "train_dataset = PartDataset(pos_pair_list, neg_pair_list, counts_dict)\n",
    "test_dataset = PartDataset(pos_pair_list, neg_pair_list, counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "b896f785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Check\n"
     ]
    }
   ],
   "source": [
    "tfidf_train_dataloader = data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "tfidf_test_dataloader = data.DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "tfidf_dataloader_dict = {'train': tfidf_train_dataloader, 'test': tfidf_test_dataloader}\n",
    "\n",
    "# Operation Check\n",
    "print('Operation Check')\n",
    "batch_iterator = iter(tfidf_train_dataloader)\n",
    "inputs, label = next(batch_iterator)\n",
    "#print(label,inputs[0][0:200]==inputs[0][200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "4c347642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfIdfNeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=21292, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=56, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=56, out_features=2, bias=True)\n",
      "    (10): Softmax(dim=None)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = TfIdfNeuralNetwork()\n",
    "#net = w2vNeuralNetwork()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=0.001, momentum=0.9)\n",
    "#cross entropy loss and stochastic gradient descent\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "9af65130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def train_model(net, dataloader_dict, criterion, optimizer, num_epoch):\n",
    "    \n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(net.state_dict())\n",
    "    best_acc = 0.0\n",
    "    net = net.to(device)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epoch))\n",
    "        print('-'*20)\n",
    "        \n",
    "        for phase in ['train', 'test']:\n",
    "            \n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "                \n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "            \n",
    "            #tqdm for progress bar\n",
    "            for inputs, labels in tqdm(dataloader_dict[phase]):\n",
    "                inputs = inputs.type(torch.FloatTensor).to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = net(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "                    \n",
    "            epoch_loss = epoch_loss / len(dataloader_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloader_dict[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(net.state_dict())\n",
    "                print(time.time())\n",
    "                torch.save(net.state_dict(), 'best_checkpoint_last_counts.pth')\n",
    "                \n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    net.load_state_dict(best_model_wts)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "efa3a7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e854f36f0244414cbf3b11d92d29f353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6593 Acc: 0.7281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fd727ba729427c8f8f8578c2cb25ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5832 Acc: 0.7831\n",
      "1639381984.4212077\n",
      "Epoch 2/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b600b2e873a49e4b854e5ae2ee73943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5290 Acc: 0.7986\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfab8fa90ebb4ebda2a38f08e29c9581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4943 Acc: 0.8265\n",
      "1639381998.5416963\n",
      "Epoch 3/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71bd2c6b53b24ab691d6cb4539273698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4765 Acc: 0.8424\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f04de3165f24959805148a08d409e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4704 Acc: 0.8445\n",
      "1639382012.330852\n",
      "Epoch 4/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b4c71c365e48adab301c73fa3301d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4518 Acc: 0.8662\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16e868619cd48dc92257c0305e88fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4541 Acc: 0.8623\n",
      "1639382026.089442\n",
      "Epoch 5/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8279000c01464070a6ce3edcab2bfb45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4371 Acc: 0.8792\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724f9c10923f4687b4c81ab419fcc2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4422 Acc: 0.8717\n",
      "1639382039.8292882\n",
      "Epoch 6/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c684c6d35421418598df8c24201cb0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4258 Acc: 0.8897\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ba4a214b794de68d8f19fc827d7b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4393 Acc: 0.8709\n",
      "Epoch 7/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0350b883b7684b34aa945e3c2e3d9b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4157 Acc: 0.8988\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c579ec0a6bfe4096bce8ef68bb07540a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4320 Acc: 0.8803\n",
      "1639382067.955607\n",
      "Epoch 8/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e87dbad59c46cdbe1ac40d8a3cc837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4060 Acc: 0.9114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ff749f925e4c228f18056383c1d511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4208 Acc: 0.8919\n",
      "1639382082.775338\n",
      "Epoch 9/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8be3bd8c23b42648b23c8933919f341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4023 Acc: 0.9125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd83164dc2649179a4911b8be0d09f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4223 Acc: 0.8901\n",
      "Epoch 10/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4d0bc1ad11404f8c065a71915414d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4003 Acc: 0.9154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c989c164e9c43f39c770f7040051e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4173 Acc: 0.8970\n",
      "1639382108.9771674\n",
      "Epoch 11/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd5ec1ce7e640b9b5c88bffb3c04074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3995 Acc: 0.9161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b424b96192242b59f7fff607a30d635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4260 Acc: 0.8836\n",
      "Epoch 12/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fb3b8178494237a44f3341131bae5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3999 Acc: 0.9140\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bbc43f820fc4c799d7e6a73fb8797d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4137 Acc: 0.8988\n",
      "1639382135.6756938\n",
      "Epoch 13/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1a9d95a83b4408b7e79f24c9c09000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3947 Acc: 0.9201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e8e30ab903427e86c0fffb3aabdac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4172 Acc: 0.8966\n",
      "Epoch 14/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac37976ea56480086096a99faa0b01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3915 Acc: 0.9234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0944e31d3a74c99b9f3b90d18f58fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4113 Acc: 0.9017\n",
      "1639382162.7648337\n",
      "Epoch 15/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc62571a31f43e39ba1684fb92fa62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3895 Acc: 0.9244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed81707355514cb28d0dd79249e04527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4127 Acc: 0.8999\n",
      "Epoch 16/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52deb7c447541448a6790d937144f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3933 Acc: 0.9205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46797a86ea224eada1285df6530b6cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4175 Acc: 0.8944\n",
      "Epoch 17/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b0bfe1548f4a598e30e20a97990775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3929 Acc: 0.9197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f951a6ad52347a4acc4148fc671619c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4195 Acc: 0.8915\n",
      "Epoch 18/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4dd45e961e4d84bf41142d14455ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3904 Acc: 0.9223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d72738ac46405b80efdd8c93397da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4283 Acc: 0.8829\n",
      "Epoch 19/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5248f88ad22c4ef2a71a87d03663df4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3773 Acc: 0.9378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1667d30e42e747db83af533f989e2559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3926 Acc: 0.9201\n",
      "1639382229.0976589\n",
      "Epoch 20/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b67d469fc054b49844cb278dd4d0db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3822 Acc: 0.9335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68be04a6088f4920adc120759967d15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4061 Acc: 0.9056\n",
      "Epoch 21/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a6e9c69b8b4ed48317a5ebdcf63aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3720 Acc: 0.9422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc9869f20de416bb851797db62b616f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3934 Acc: 0.9165\n",
      "Epoch 22/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f102ba8591274e7eb0189055f49bb9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3663 Acc: 0.9483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc22f47276a414299a718350803bc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3822 Acc: 0.9306\n",
      "1639382268.576571\n",
      "Epoch 23/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1945284f75504657aba1bf0afd9934f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3626 Acc: 0.9512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1480c7b5604061b56539d4d1e977c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3896 Acc: 0.9234\n",
      "Epoch 24/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bd9e6def774f67915a3ce3dbbfa729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3584 Acc: 0.9566\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c099b4095f49599958a05df648ff76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3832 Acc: 0.9291\n",
      "Epoch 25/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f8257653d34a6286a80d2c70d6a25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3598 Acc: 0.9544\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6bc64e8d64844faab63e4200e659d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3903 Acc: 0.9223\n",
      "Epoch 26/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3b3ebf9e374560b9ecee7c318a1926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3610 Acc: 0.9534\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24099ec03b994ac1b8438b9190b5bdba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3976 Acc: 0.9147\n",
      "Epoch 27/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f6e60ac4264d20825cbcbce81ebc1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3658 Acc: 0.9476\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7404c8c3351d4eaebe8e3136258687f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3936 Acc: 0.9179\n",
      "Epoch 28/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99739d97a44a4811884deaf6e370ce99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3589 Acc: 0.9548\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cebc51929e4e949b8c782ba851d440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3801 Acc: 0.9324\n",
      "1639382346.5274894\n",
      "Epoch 29/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f13da9d667944369000e658f701be95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3545 Acc: 0.9591\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28ed32786514738a4ef7bf1322cb4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3790 Acc: 0.9342\n",
      "1639382360.5031013\n",
      "Epoch 30/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57139d19642e40daaf442b5c4eb5e43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3547 Acc: 0.9591\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6e2d021e9c400f904849a6ee05b128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3815 Acc: 0.9313\n",
      "Epoch 31/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f6e53ed5fd46a7b1d1a858b33f7eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3551 Acc: 0.9588\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993c26a475e34688a933694823408a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3837 Acc: 0.9273\n",
      "Epoch 32/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65b017dfe124427b2f839e7f8f0dcfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3546 Acc: 0.9591\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9472454cde4733b3b2068cdcb6ce59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3817 Acc: 0.9284\n",
      "Epoch 33/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c786a0c5e944b1b81e27a06a185dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3515 Acc: 0.9620\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bed2dc33c440bfaf39329b03f06320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3755 Acc: 0.9375\n",
      "1639382412.5924015\n",
      "Epoch 34/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590322ddf9e84adfaa21f99140d04634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3507 Acc: 0.9628\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c09554d767a44369cc1a7f68236ad4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3768 Acc: 0.9367\n",
      "Epoch 35/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ed3c14ecba4627a1cad2a22a14b8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3505 Acc: 0.9631\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80b6e7b84c94c8ebf82e70b8df7314f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3837 Acc: 0.9270\n",
      "Epoch 36/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7169ede49b348378d981e2aac12a848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3554 Acc: 0.9581\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155ca347fce9444e9320100a44f1f2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3872 Acc: 0.9237\n",
      "Epoch 37/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed7444845e24e19a79515838fbe2aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3556 Acc: 0.9577\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f110a176dab4d3a8e68ff4aa550eb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3891 Acc: 0.9219\n",
      "Epoch 38/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db27f38cd894dcd8be97e506db38d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3502 Acc: 0.9631\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131a7d2b7a2d488d9d3e35895d2d5a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3729 Acc: 0.9393\n",
      "1639382477.5874476\n",
      "Epoch 39/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c460bd52a2e5483eb41eee78893f24fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3484 Acc: 0.9646\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b0702716ce4abd8c7d358570976084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3751 Acc: 0.9375\n",
      "Epoch 40/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e7e7a92d554ba891c4e2e868a0b362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3512 Acc: 0.9620\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee59f1f4fde4e4081ba67e615e89346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3898 Acc: 0.9201\n",
      "Training complete in 8m 53s\n",
      "Best val Acc: 0.939262\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 40\n",
    "net = train_model(net, tfidf_dataloader_dict, criterion, optimizer, num_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fed10f",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509203c",
   "metadata": {},
   "source": [
    "#### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "5168e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datapath = 'Stage_2\\dataPublicComplete_s2\\dataPublicComplete'\n",
    "datapath = 'dataTrainComplete'\n",
    "txt_fnames = [splitext(f)[0] for f in listdir(datapath) if isfile(join(datapath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "f0406180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "df = pd.DataFrame([])\n",
    "for fname in txt_fnames:\n",
    "    txt = open(datapath+'/'+fname+'.txt', \"r\",encoding=\"utf-8\")\n",
    "    content = txt.read()\n",
    "    df = pd.concat([df, pd.Series([jieba.lcut(content, cut_all=False)])], axis = 0)\n",
    "df.columns = ['tokenization']\n",
    "df['name'] = txt_fnames\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "6b1aeb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping all the docs\n",
    "for index, row in df.iterrows():\n",
    "    row['tokenization'] = keyword_normalization(df.iloc[index]['tokenization'], vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "920393cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat tokenized text with space\n",
    "df2list = df.tokenization.tolist()\n",
    "cut_corpus = []\n",
    "for i in df2list:\n",
    "    cut_corpus.append(' '.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "6799fd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cut_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "6c2b0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing input\n",
    "# for CountVectorizer module to calculate the term frequency\n",
    "counts = count_vect.transform(cut_corpus).toarray()\n",
    "count_feature = count_vect.get_feature_names()\n",
    "# for TfidfVectorizer module to convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "tfidfs = tfidf_vect.transform(cut_corpus).toarray()\n",
    "tfidf_feature = tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c98076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_feature = np.array([])\n",
    "for i in np.arange(len(cut_corpus)):\n",
    "    if word2vec_feature.size == 0:\n",
    "        word2vec_feature = np.array([get_vector(cut_corpus[i])])\n",
    "    else:\n",
    "        # concat the two vectors by different columns\n",
    "        word2vec_feature = np.concatenate((word2vec_feature,np.array([get_vector(cut_corpus[i])])), axis = 0)\n",
    "# word2vec_feature.shape = (421, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2082fbe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1284/852056315.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# using these code as embedding features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform',\n\u001b[0m\u001b[0;32m      3\u001b[0m                        \u001b[0membeddings_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                        embeddings_constraint=None, mask_zero=False, input_length=None)\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex2vec\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# using these code as embedding features\n",
    "keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform',\n",
    "                       embeddings_regularizer=None, activity_regularizer=None,\n",
    "                       embeddings_constraint=None, mask_zero=False, input_length=None)\n",
    "model.add(Embedding(index2vec.shape[0], index2vec.shape[1], weights=[index2vec], trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "a6075a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "pair_list = []\n",
    "#Deprecated\n",
    "for fname1 in txt_fnames:\n",
    "    for fname2 in txt_fnames:\n",
    "        if(fname1 == fname2):continue\n",
    "        else:\n",
    "            labels[(fname1,fname2)] = 0\n",
    "            pair_list.append((fname1,fname2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "b3e94c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# decide which feature you want, tfidf or countvector or others\\ndef construct_test_input_vector(adapted_vector, tokenized_df, test_pair_list):\\n    input_vectors = np.array([])\\n    for i in np.arange(len(test_pair_list)):\\n        Test, Ref = test_pair_list[i] # order of docs\\n        Test_vec = adapted_vector[tokenized_df[tokenized_df['name']==Test].index[0]] # from order of doc to find out the order of vectors\\n        Ref_vec = adapted_vector[tokenized_df[tokenized_df['name']==Ref].index[0]] # same\\n        temp_vectors = np.concatenate(([Test_vec],[Ref_vec]), axis = 1) # concat the two vectors in same row\\n        if input_vectors.size == 0:\\n            input_vectors = temp_vectors\\n        else:\\n            input_vectors = np.concatenate((input_vectors,temp_vectors)) # concat the two vectors by different columns\\n    return input_vectors\\n\""
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# decide which feature you want, tfidf or countvector or others\n",
    "def construct_test_input_vector(adapted_vector, tokenized_df, test_pair_list):\n",
    "    input_vectors = np.array([])\n",
    "    for i in np.arange(len(test_pair_list)):\n",
    "        Test, Ref = test_pair_list[i] # order of docs\n",
    "        Test_vec = adapted_vector[tokenized_df[tokenized_df['name']==Test].index[0]] # from order of doc to find out the order of vectors\n",
    "        Ref_vec = adapted_vector[tokenized_df[tokenized_df['name']==Ref].index[0]] # same\n",
    "        temp_vectors = np.concatenate(([Test_vec],[Ref_vec]), axis = 1) # concat the two vectors in same row\n",
    "        if input_vectors.size == 0:\n",
    "            input_vectors = temp_vectors\n",
    "        else:\n",
    "            input_vectors = np.concatenate((input_vectors,temp_vectors)) # concat the two vectors by different columns\n",
    "    return input_vectors\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "a5ea7751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = construct_test_input_vector(tfidfs, df, pair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1b700e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560\n",
      "560\n",
      "560\n"
     ]
    }
   ],
   "source": [
    "tfidf_dict = {}\n",
    "for idx,vec in enumerate(tfidfs):\n",
    "    tfidf_dict[df.iloc[idx]['name']] = vec\n",
    "print(len(tfidf_dict))\n",
    "w2v_dict = {}\n",
    "for idx,vec in enumerate(word2vec_feature):\n",
    "    w2v_dict[df.iloc[idx]['name']] = vec\n",
    "print(len(w2v_dict))\n",
    "counts_dict = {}\n",
    "for idx,vec in enumerate(counts):\n",
    "    counts_dict[df.iloc[idx]['name']] = vec\n",
    "print(len(counts_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f4a2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_tfidf,net_w2v,net_counts = TfIdfNeuralNetwork(),w2vNeuralNetwork(),TfIdfNeuralNetwork()\n",
    "net_tfidf.load_state_dict(torch.load('best_checkpoint_last_TFIDF.pth'))\n",
    "net_w2v.load_state_dict(torch.load('best_checkpoint_last_w2v.pth'))\n",
    "net_counts.load_state_dict(torch.load('best_checkpoint_last_counts.pth'))\n",
    "net_tfidf = net_tfidf.to(device)\n",
    "net_w2v = net_w2v.to(device)\n",
    "net_counts = net_counts.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b10b116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c332162bf13a4faab924b17f01a95058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Renewrr\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5209be318eb747fc8c3540235d11f882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973e767ca71540c6a83f50a870d46817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "out_counts = []\n",
    "with torch.no_grad():\n",
    "    for test,ref in tqdm(pair_list):\n",
    "        input_vec = torch.tensor(np.concatenate((counts_dict[test], counts_dict[ref]), axis=None))\n",
    "        input_vec = input_vec.type(torch.FloatTensor).to(device)\n",
    "        lbl = net_counts(input_vec)\n",
    "        out_counts.append([(test,ref),lbl.cpu()])\n",
    "out_tfidf = []\n",
    "with torch.no_grad():\n",
    "    for test,ref in tqdm(pair_list):\n",
    "        input_vec = torch.tensor(np.concatenate((tfidf_dict[test], tfidf_dict[ref]), axis=None))\n",
    "        input_vec = input_vec.type(torch.FloatTensor).to(device)\n",
    "        lbl = net_tfidf(input_vec)\n",
    "        out_tfidf.append([(test,ref),lbl.cpu()])\n",
    "out_w2v = []\n",
    "with torch.no_grad():\n",
    "    for test,ref in tqdm(pair_list):\n",
    "        input_vec = torch.tensor(np.concatenate((w2v_dict[test], w2v_dict[ref]), axis=None))\n",
    "        input_vec = input_vec.type(torch.FloatTensor).to(device)\n",
    "        lbl = net_w2v(input_vec)\n",
    "        out_w2v.append([(test,ref),lbl.cpu()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "673978a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('10', '727'), tensor([0.6064, 0.3936])],\n",
       " [('10', '73'), tensor([0.5423, 0.4577])],\n",
       " [('10', '730'), tensor([0.5866, 0.4134])],\n",
       " [('10', '732'), tensor([0.5894, 0.4106])],\n",
       " [('10', '733'), tensor([0.5926, 0.4074])],\n",
       " [('10', '740'), tensor([0.6210, 0.3790])],\n",
       " [('10', '741'), tensor([0.5922, 0.4078])],\n",
       " [('10', '744'), tensor([0.5860, 0.4140])],\n",
       " [('10', '746'), tensor([0.5769, 0.4231])],\n",
       " [('10', '747'), tensor([0.5958, 0.4042])]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "127c3e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1172, 11025, 18320)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_tfidf = []\n",
    "for o in out_tfidf:\n",
    "    if(o[1][1] > 0.3):better_tfidf.append(o[0])\n",
    "better_counts = []\n",
    "for o in out_counts:\n",
    "    if(o[1][1] > 0.99):better_counts.append(o[0])\n",
    "better_w2v = []\n",
    "for o in out_w2v:\n",
    "    if(o[1][1] > 0.5):better_w2v.append(o[0])\n",
    "len(better_tfidf),len(better_counts),len(better_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4db4c39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 1172\n",
      "TFIDF - Recall: 0.09978308026030369 Precision: 0.11774744027303755 F1 0.10802348336594912\n",
      "682 11025\n",
      "Counts - Recall: 0.49313087490961677 Precision: 0.061859410430839 F1 0.10992907801418439\n",
      "137 18320\n",
      "W2V - Recall: 0.09906001446131597 Precision: 0.0074781659388646286 F1 0.01390651169872608\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for o in better_tfidf:\n",
    "    if(o in pos_labels):count+=1\n",
    "recall,precision = count/len(pos_labels),count/len(better_tfidf)\n",
    "print(count,len(better_tfidf))\n",
    "print('TFIDF - Recall:',recall,'Precision:',precision,'F1',2*(recall*precision)/(recall+precision))\n",
    "\n",
    "count = 0\n",
    "for o in better_counts:\n",
    "    if(o in pos_labels):count+=1\n",
    "recall,precision = count/len(pos_labels),count/len(better_counts)\n",
    "print(count,len(better_counts))\n",
    "print('Counts - Recall:',recall,'Precision:',precision,'F1',2*(recall*precision)/(recall+precision))\n",
    "\n",
    "count = 0\n",
    "for o in better_w2v:\n",
    "    if(o in pos_labels):count+=1\n",
    "recall,precision = count/len(pos_labels),count/len(better_w2v)\n",
    "print(count,len(better_w2v))\n",
    "print('W2V - Recall:',recall,'Precision:',precision,'F1',2*(recall*precision)/(recall+precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefac875",
   "metadata": {},
   "source": [
    "#### classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621427c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "5a9b014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "print(len(better))\n",
    "with open('val_w2v.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow([\"Test\"]+[\"Reference\"])\n",
    "    for row in better:  \n",
    "        spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d72ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
