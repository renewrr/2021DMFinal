{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7ebc1624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "67cd8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join,splitext\n",
    "t_dir = 'dataTrainComplete'\n",
    "txt_fnames = [splitext(f)[0] for f in listdir(t_dir) if isfile(join(t_dir, f))] #Article filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "d6bf5376",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_list = open('Keywords/02crop.list.csv', \"r\",encoding='UTF-8-sig')\n",
    "crop = crop_list.read()\n",
    "crop_line_sep = crop.splitlines()\n",
    "\n",
    "pest_list = open('Keywords/02pest.list.csv', \"r\",encoding='UTF-8-sig')\n",
    "pest = pest_list.read()\n",
    "pest_line_sep = pest.splitlines()\n",
    "\n",
    "chem_list = open('Keywords/02chem.list.csv', \"r\",encoding='UTF-8-sig')\n",
    "chem = chem_list.read()\n",
    "chem_line_sep = chem.splitlines()\n",
    "#Keywords split by lines, keyword with more than one entry will be on the same line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "9ec20f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import csv\n",
    "vector_dict = {}\n",
    "word_list = []\n",
    "#Keyword lookup with keyword as key and vector index as value\n",
    "for idx,line in enumerate(chain(crop_line_sep,pest_line_sep,chem_line_sep)):\n",
    "    l = line.split(',')\n",
    "    for word in l:\n",
    "        #Some line will have more than one entry, which should have the same vector index\n",
    "        if(word == ''):continue\n",
    "        jieba.add_word(word) #Each keyword is added to jieba\n",
    "        vector_dict[word] = l[0] # same meaning of different word will have same key number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "5e36b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding user dictionary\n",
    "userdict = ['多變', '溫差', '防檢局', '果農', '防範', '颱風', '台中市', '臺中市',\n",
    "            '發布', '發佈', '復育', '轄區', '臺南區', '開花期', '莫拉克', '桃園市', '新竹縣']\n",
    "for word in userdict:\n",
    "    jieba.add_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "553c903a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenization\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([])\n",
    "for fname in txt_fnames:\n",
    "    txt = open(t_dir+'/'+fname+'.txt', \"r\",encoding=\"utf-8\")\n",
    "    content = txt.read()\n",
    "    df = pd.concat([df, pd.Series([jieba.lcut(content, cut_all=False)])], axis = 0)\n",
    "df.columns = ['tokenization']\n",
    "df['name'] = txt_fnames\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "ac9c6960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[梅雨季, 來臨, ，, 文旦, 黑點病, 易, 發生, ，, 請, 注意, 病徵, ，, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[天氣, 多變, 溫差, 大, ，, 近山區, 及, 偏施, 氮肥, 田區, 稻熱病, 發病...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[新聞稿, -, 稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, ...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, 防治, \\n, ...</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[乍暖, 還寒, ，, 防檢局, 籲請, 農友, 加強, 防治, 稻熱病, \\n, 農委會,...</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>[苗栗, 區農業, 改良, 場, 發佈, 水稻, 白葉枯病, 警報, \\n, 糧食, 作物,...</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>[雨, 後, 適合, 稻熱病, 發生, ，, 請持續, 進行, 監測, 並指導, 農民, 防...</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>[新, 入侵, 果實蠅, 緊急, 撲滅, 模擬, 演習,  ,  , 新聞稿, \\n, 新,...</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>[梨木蝨, 危害, ，, 請, 農友, 注意, 防範, \\n, 梨木蝨, 危害, ，, 請,...</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>[防範, 梨木蝨, 危害, ，, 請, 農友, 配合, 實施, 共同, 防治, \\n, 行政...</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tokenization  name\n",
       "0    [梅雨季, 來臨, ，, 文旦, 黑點病, 易, 發生, ，, 請, 注意, 病徵, ，, ...     1\n",
       "1    [天氣, 多變, 溫差, 大, ，, 近山區, 及, 偏施, 氮肥, 田區, 稻熱病, 發病...    10\n",
       "2    [新聞稿, -, 稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, ...  1000\n",
       "3    [稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, 防治, \\n, ...  1005\n",
       "4    [乍暖, 還寒, ，, 防檢局, 籲請, 農友, 加強, 防治, 稻熱病, \\n, 農委會,...  1007\n",
       "..                                                 ...   ...\n",
       "555  [苗栗, 區農業, 改良, 場, 發佈, 水稻, 白葉枯病, 警報, \\n, 糧食, 作物,...   986\n",
       "556  [雨, 後, 適合, 稻熱病, 發生, ，, 請持續, 進行, 監測, 並指導, 農民, 防...   988\n",
       "557  [新, 入侵, 果實蠅, 緊急, 撲滅, 模擬, 演習,  ,  , 新聞稿, \\n, 新,...   992\n",
       "558  [梨木蝨, 危害, ，, 請, 農友, 注意, 防範, \\n, 梨木蝨, 危害, ，, 請,...   997\n",
       "559  [防範, 梨木蝨, 危害, ，, 請, 農友, 配合, 實施, 共同, 防治, \\n, 行政...   998\n",
       "\n",
       "[560 rows x 2 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "54f747a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the different word but have same meaning into one word\n",
    "def keyword_normalization(list_to_be_mapped, key_dict):\n",
    "    return [key_dict.get(a) if key_dict.get(a) else a for a in list_to_be_mapped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "cb2abb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping all the docs\n",
    "for index, row in df.iterrows():\n",
    "    row['tokenization'] = keyword_normalization(df.iloc[index]['tokenization'], vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0267950f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[梅雨季, 來臨, ，, 文旦柚, 黑點病, 易, 發生, ，, 請, 注意, 病徵, ，,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[天氣, 多變, 溫差, 大, ，, 近山區, 及, 偏施, 氮肥, 田區, 稻熱病, 發病...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[新聞稿, -, 稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, ...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, 防治, \\n, ...</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[乍暖, 還寒, ，, 防檢局, 籲請, 農友, 加強, 防治, 稻熱病, \\n, 農委會,...</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>[苗栗, 區農業, 改良, 場, 發佈, 水稻, 白葉枯病, 警報, \\n, 糧食, 作物,...</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>[雨, 後, 適合, 稻熱病, 發生, ，, 請持續, 進行, 監測, 並指導, 農民, 防...</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>[新, 入侵, 果實蠅, 緊急, 撲滅, 模擬, 演習, 三泰芬, 三泰芬, 新聞稿, \\n...</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>[梨木蝨, 危害, ，, 請, 農友, 注意, 防範, \\n, 梨木蝨, 危害, ，, 請,...</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>[防範, 梨木蝨, 危害, ，, 請, 農友, 配合, 實施, 共同, 防治, \\n, 行政...</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tokenization  name\n",
       "0    [梅雨季, 來臨, ，, 文旦柚, 黑點病, 易, 發生, ，, 請, 注意, 病徵, ，,...     1\n",
       "1    [天氣, 多變, 溫差, 大, ，, 近山區, 及, 偏施, 氮肥, 田區, 稻熱病, 發病...    10\n",
       "2    [新聞稿, -, 稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, ...  1000\n",
       "3    [稻熱病, 進入, 好, 發季節, ，, 防檢局, 籲請, 農友, 加強, 防治, \\n, ...  1005\n",
       "4    [乍暖, 還寒, ，, 防檢局, 籲請, 農友, 加強, 防治, 稻熱病, \\n, 農委會,...  1007\n",
       "..                                                 ...   ...\n",
       "555  [苗栗, 區農業, 改良, 場, 發佈, 水稻, 白葉枯病, 警報, \\n, 糧食, 作物,...   986\n",
       "556  [雨, 後, 適合, 稻熱病, 發生, ，, 請持續, 進行, 監測, 並指導, 農民, 防...   988\n",
       "557  [新, 入侵, 果實蠅, 緊急, 撲滅, 模擬, 演習, 三泰芬, 三泰芬, 新聞稿, \\n...   992\n",
       "558  [梨木蝨, 危害, ，, 請, 農友, 注意, 防範, \\n, 梨木蝨, 危害, ，, 請,...   997\n",
       "559  [防範, 梨木蝨, 危害, ，, 請, 農友, 配合, 實施, 共同, 防治, \\n, 行政...   998\n",
       "\n",
       "[560 rows x 2 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "181f312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat tokenized text with space\n",
    "df2list = df.tokenization.tolist()\n",
    "cut_corpus = []\n",
    "for i in df2list:\n",
    "    cut_corpus.append(' '.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "9bde37a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cut_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "5c4a9bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'梅雨季 來臨 ， 文旦柚 黑點病 易 發生 ， 請 注意 病徵 ， 以及 早加強 防治 措施 。 \\n 5 月 已 進入 梅雨季 節 ， 近日 連續 降雨 ， 為 文旦柚 黑點病 開始 感染 的 時機 ， 往年 文旦柚 在 經過 4 - 6 月 的 春雨 及 梅雨季 後 ， 原來 長 得 亮麗 的 果實 外表 ， 會 開始 出現 許多 小黑 點 ， 現在 文旦柚 已 開始 進入 中果期 ， 花蓮區 農業 改良 場呼籲 應 注意 防治 。 \\n 除 冬季 清園 作業外 ， 在 4 - 8 月 時應 每月 施用 一次 56% 貝芬 硫 \\x7f 可濕性 粉劑 800 倍 、 或 22.7% \\x7f 硫 \\x7f 水懸劑 1000 倍 、 或 80% 鋅錳乃浦 500 倍 、 或 33% 鋅錳乃浦 500 倍 等 政府 核准 登記 使用 之藥劑 防治 ， 並依 登記 使用 方法 使用 ， 尤其 雨前 及雨後要 特別 加強 防治 ， 若遇 連續 降雨 時則 可 利用 間 歇 時 分區 進行 施藥 以 即 時 達 到 防治效果 。 \\n'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "3b8af794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# functions for analysis module\n",
    "\n",
    "# CountVector\n",
    "def CountVectorizer_model(data):\n",
    "    count_vect = CountVectorizer()\n",
    "    counts = count_vect.fit_transform(data).toarray() # type: np.array\n",
    "    # names per every features: count_vect.get_feature_names(), type: list\n",
    "    return count_vect, count_vect.get_feature_names(), counts\n",
    "\n",
    "# TF-IDF\n",
    "def TfidfVectorizer_model(data):\n",
    "    tfidf_vect = TfidfVectorizer()\n",
    "    tfidfs = tfidf_vect.fit_transform(data).toarray()\n",
    "    return tfidf_vect, tfidf_vect.get_feature_names(), tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c5f73da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Renewrr\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# for CountVectorizer module to calculate the term frequency\n",
    "count_vect, count_feature, counts = CountVectorizer_model(cut_corpus)\n",
    "# for TfidfVectorizer module to convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "tfidf_vect, tfidf_feature, tfidfs = TfidfVectorizer_model(cut_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2d31d239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "741ef1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10646"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "ca8864da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.12346158, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.09047349, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "cb46a12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '02',\n",
       " '03',\n",
       " '037',\n",
       " '039',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '069',\n",
       " '07',\n",
       " '08',\n",
       " '0800',\n",
       " '0800039131',\n",
       " '089',\n",
       " '090',\n",
       " '0905',\n",
       " '0932',\n",
       " '0935425837',\n",
       " '095',\n",
       " '0972',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10004',\n",
       " '1000x',\n",
       " '100g',\n",
       " '101',\n",
       " '103',\n",
       " '104',\n",
       " '105',\n",
       " '1051102',\n",
       " '106',\n",
       " '108',\n",
       " '109',\n",
       " '11',\n",
       " '110',\n",
       " '118',\n",
       " '12',\n",
       " '1200',\n",
       " '12000',\n",
       " '127',\n",
       " '13',\n",
       " '130',\n",
       " '1300',\n",
       " '131',\n",
       " '139',\n",
       " '14',\n",
       " '145',\n",
       " '146',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '154',\n",
       " '1542',\n",
       " '15mm',\n",
       " '16',\n",
       " '1600',\n",
       " '1684',\n",
       " '1686',\n",
       " '17',\n",
       " '1700',\n",
       " '17512',\n",
       " '1783',\n",
       " '18',\n",
       " '1800',\n",
       " '1845',\n",
       " '19',\n",
       " '192',\n",
       " '1990',\n",
       " '1mm',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2002',\n",
       " '2006',\n",
       " '20492',\n",
       " '205',\n",
       " '206',\n",
       " '20for',\n",
       " '20japan1021226',\n",
       " '21',\n",
       " '22',\n",
       " '222111',\n",
       " '224',\n",
       " '23',\n",
       " '23431471',\n",
       " '23431473',\n",
       " '236583',\n",
       " '236619',\n",
       " '24',\n",
       " '25',\n",
       " '250',\n",
       " '2500',\n",
       " '250g',\n",
       " '251',\n",
       " '256',\n",
       " '2566',\n",
       " '26',\n",
       " '260',\n",
       " '2665',\n",
       " '2679526',\n",
       " '268',\n",
       " '27',\n",
       " '272',\n",
       " '277',\n",
       " '28',\n",
       " '29',\n",
       " '2face',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30000',\n",
       " '301',\n",
       " '302',\n",
       " '303',\n",
       " '305',\n",
       " '306',\n",
       " '307',\n",
       " '308',\n",
       " '309',\n",
       " '31',\n",
       " '310',\n",
       " '311',\n",
       " '313',\n",
       " '315',\n",
       " '32',\n",
       " '320',\n",
       " '321',\n",
       " '322046',\n",
       " '323',\n",
       " '325015',\n",
       " '325110',\n",
       " '327',\n",
       " '327904',\n",
       " '33',\n",
       " '3307',\n",
       " '333mp',\n",
       " '34',\n",
       " '35',\n",
       " '350',\n",
       " '351',\n",
       " '358616',\n",
       " '358618',\n",
       " '36',\n",
       " '360',\n",
       " '3600',\n",
       " '361786',\n",
       " '3691ctnode',\n",
       " '37',\n",
       " '370',\n",
       " '3751574',\n",
       " '38',\n",
       " '382',\n",
       " '39',\n",
       " '390',\n",
       " '3mm',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '409',\n",
       " '41',\n",
       " '411',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '441',\n",
       " '443',\n",
       " '45',\n",
       " '450',\n",
       " '46',\n",
       " '460',\n",
       " '47',\n",
       " '476',\n",
       " '4768216',\n",
       " '48',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '500g',\n",
       " '52',\n",
       " '525g',\n",
       " '526',\n",
       " '53',\n",
       " '53715',\n",
       " '5371574',\n",
       " '54',\n",
       " '5400',\n",
       " '55',\n",
       " '552',\n",
       " '5523270',\n",
       " '5523307',\n",
       " '558124',\n",
       " '56',\n",
       " '58',\n",
       " '590',\n",
       " '5912901',\n",
       " '5912905',\n",
       " '5x10',\n",
       " '60',\n",
       " '600',\n",
       " '6000',\n",
       " '61',\n",
       " '613',\n",
       " '62',\n",
       " '63',\n",
       " '632',\n",
       " '634',\n",
       " '64',\n",
       " '65',\n",
       " '650',\n",
       " '6622274',\n",
       " '67',\n",
       " '68',\n",
       " '683',\n",
       " '70',\n",
       " '700',\n",
       " '700pcu',\n",
       " '71',\n",
       " '72',\n",
       " '72000',\n",
       " '7229461',\n",
       " '73',\n",
       " '730',\n",
       " '73000',\n",
       " '737',\n",
       " '738',\n",
       " '7389060',\n",
       " '7389158',\n",
       " '74',\n",
       " '744',\n",
       " '75',\n",
       " '750',\n",
       " '7500',\n",
       " '76',\n",
       " '7642',\n",
       " '7665',\n",
       " '7665page',\n",
       " '77',\n",
       " '7746728',\n",
       " '7746741',\n",
       " '7746755',\n",
       " '7746761',\n",
       " '78',\n",
       " '79',\n",
       " '7cfu',\n",
       " '7g',\n",
       " '80',\n",
       " '800',\n",
       " '8000',\n",
       " '81',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '850',\n",
       " '8521108',\n",
       " '8521114',\n",
       " '8521493',\n",
       " '8535915',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '880',\n",
       " '89',\n",
       " '90',\n",
       " '900',\n",
       " '901',\n",
       " '9030',\n",
       " '9031',\n",
       " '9060',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '9632',\n",
       " '97',\n",
       " '977',\n",
       " '98',\n",
       " '9899739',\n",
       " '99',\n",
       " '9cfu',\n",
       " 'acerialitchi',\n",
       " 'ageratumyellowveinvirus',\n",
       " 'agral',\n",
       " 'annonasquamosa',\n",
       " 'anonaepestisbengalella',\n",
       " 'aphiq',\n",
       " 'app',\n",
       " 'articles',\n",
       " 'aspx',\n",
       " 'ayvv',\n",
       " 'banana',\n",
       " 'baphig',\n",
       " 'baphiq',\n",
       " 'blackrotofpapaya',\n",
       " 'c3',\n",
       " 'catid',\n",
       " 'cmv',\n",
       " 'coa',\n",
       " 'cs',\n",
       " 'ct',\n",
       " 'cucumbermosaicvirus',\n",
       " 'drug',\n",
       " 'dug',\n",
       " 'faw',\n",
       " 'file',\n",
       " 'filelink1fontsize',\n",
       " 'fontdivid',\n",
       " 'formmap',\n",
       " 'fp2000',\n",
       " 'fusariummangiferae',\n",
       " 'g1',\n",
       " 'googlemap',\n",
       " 'gov',\n",
       " 'hdais',\n",
       " 'hdares',\n",
       " 'htdocs',\n",
       " 'htm',\n",
       " 'htmlarea',\n",
       " 'http',\n",
       " 'https',\n",
       " 'id',\n",
       " 'index',\n",
       " 'insecticides',\n",
       " 'kdais',\n",
       " 'keifer',\n",
       " 'line',\n",
       " 'linfa',\n",
       " 'list',\n",
       " 'longanwitchsbroom',\n",
       " 'longwang',\n",
       " 'mango',\n",
       " 'mango1020812',\n",
       " 'mdaes',\n",
       " 'mdais',\n",
       " 'menuitem1',\n",
       " 'menuitem5',\n",
       " 'meskell',\n",
       " 'mm',\n",
       " 'news',\n",
       " 'newsdetailviews',\n",
       " 'nsf',\n",
       " 'openform',\n",
       " 'org',\n",
       " 'otserv2',\n",
       " 'pdf',\n",
       " 'pe',\n",
       " 'peronophythoralitchii',\n",
       " 'pess',\n",
       " 'pesticide',\n",
       " 'ph6',\n",
       " 'philusantennatus',\n",
       " 'phis',\n",
       " 'php',\n",
       " 'phyllotretastriolata',\n",
       " 'phytoplasma',\n",
       " 'planococcusminor',\n",
       " 'plant',\n",
       " 'porbenazole',\n",
       " 'potatovirusy',\n",
       " 'potect',\n",
       " 'ppm',\n",
       " 'ppmtable',\n",
       " 'ppmtale',\n",
       " 'prevention',\n",
       " 'protect',\n",
       " 'pseudomonassyringae',\n",
       " 'pvy',\n",
       " 'pythium',\n",
       " 'pythiumspp',\n",
       " 'rhizoctonia',\n",
       " 'rhizoctoniasolani',\n",
       " 'riced',\n",
       " 'rid',\n",
       " 'scirtothripsdorsalis',\n",
       " 'sn',\n",
       " 'streptomycin',\n",
       " 'sug',\n",
       " 'tacti',\n",
       " 'tactri',\n",
       " 'tdais',\n",
       " 'tecloftalam',\n",
       " 'tetracycline',\n",
       " 'theme',\n",
       " 'tndais',\n",
       " 'tomatomosaicvirus',\n",
       " 'tomatospottedwiltvirus',\n",
       " 'tomatoyellowleafcurlvirus',\n",
       " 'tomv',\n",
       " 'tswv',\n",
       " 'tw',\n",
       " 'tylcv',\n",
       " 'vesicatoria',\n",
       " 'view',\n",
       " 'we',\n",
       " 'web',\n",
       " 'webevery',\n",
       " 'wp1500',\n",
       " 'ws',\n",
       " 'wsite',\n",
       " 'www',\n",
       " 'xanthomonascampestrispv',\n",
       " 'xitem',\n",
       " '一久',\n",
       " '一二',\n",
       " '一五',\n",
       " '一些',\n",
       " '一個',\n",
       " '一個蟲',\n",
       " '一傳真',\n",
       " '一傷口',\n",
       " '一公頃',\n",
       " '一六號',\n",
       " '一分',\n",
       " '一則',\n",
       " '一千一百',\n",
       " '一千零五',\n",
       " '一半',\n",
       " '一圈',\n",
       " '一堆',\n",
       " '一大',\n",
       " '一天',\n",
       " '一季',\n",
       " '一定',\n",
       " '一害蟲',\n",
       " '一小',\n",
       " '一層',\n",
       " '一帶',\n",
       " '一年',\n",
       " '一幼葉',\n",
       " '一排',\n",
       " '一斑',\n",
       " '一日',\n",
       " '一旦',\n",
       " '一時',\n",
       " '一期',\n",
       " '一期稻作',\n",
       " '一果',\n",
       " '一株',\n",
       " '一條',\n",
       " '一次',\n",
       " '一步',\n",
       " '一段',\n",
       " '一波',\n",
       " '一波接',\n",
       " '一波鋒面',\n",
       " '一片',\n",
       " '一生',\n",
       " '一百',\n",
       " '一百五十',\n",
       " '一直',\n",
       " '一種',\n",
       " '一級',\n",
       " '一致',\n",
       " '一般',\n",
       " '一般而言',\n",
       " '一蟲',\n",
       " '一行',\n",
       " '一賃',\n",
       " '一起',\n",
       " '一路',\n",
       " '一輪',\n",
       " '一連',\n",
       " '一週',\n",
       " '一邊',\n",
       " '一鉀',\n",
       " '一鐵樹',\n",
       " '一陣',\n",
       " '一面',\n",
       " '一項',\n",
       " '一點',\n",
       " '一齡',\n",
       " '丁基加保扶',\n",
       " '七五',\n",
       " '七分',\n",
       " '七天',\n",
       " '七年',\n",
       " '七張',\n",
       " '七日',\n",
       " '七月',\n",
       " '七股',\n",
       " '七至',\n",
       " '七路',\n",
       " '三一',\n",
       " '三個',\n",
       " '三元',\n",
       " '三元硫酸銅',\n",
       " '三到',\n",
       " '三則',\n",
       " '三化螟',\n",
       " '三十',\n",
       " '三十五',\n",
       " '三十度',\n",
       " '三十日',\n",
       " '三千',\n",
       " '三四',\n",
       " '三塞唑',\n",
       " '三大',\n",
       " '三層',\n",
       " '三得芬',\n",
       " '三星',\n",
       " '三月',\n",
       " '三次',\n",
       " '三民',\n",
       " '三氟敏',\n",
       " '三氟派瑞',\n",
       " '三氯松',\n",
       " '三泰芬',\n",
       " '三泰隆',\n",
       " '三灣',\n",
       " '三片',\n",
       " '三種',\n",
       " '三縣',\n",
       " '三至',\n",
       " '三處',\n",
       " '三要素',\n",
       " '三變',\n",
       " '三賽唑',\n",
       " '三路',\n",
       " '三週',\n",
       " '三項',\n",
       " '三齡',\n",
       " '上下',\n",
       " '上並',\n",
       " '上之病',\n",
       " '上令',\n",
       " '上以',\n",
       " '上位',\n",
       " '上傳',\n",
       " '上出',\n",
       " '上列',\n",
       " '上則',\n",
       " '上化',\n",
       " '上升',\n",
       " '上午',\n",
       " '上及',\n",
       " '上噴',\n",
       " '上均',\n",
       " '上市',\n",
       " '上常',\n",
       " '上應',\n",
       " '上方',\n",
       " '上旬',\n",
       " '上會出',\n",
       " '上會產生',\n",
       " '上產卵',\n",
       " '上產生',\n",
       " '上病',\n",
       " '上移',\n",
       " '上端',\n",
       " '上策',\n",
       " '上經',\n",
       " '上維持',\n",
       " '上網',\n",
       " '上要',\n",
       " '上覆',\n",
       " '上轉',\n",
       " '上述',\n",
       " '上部',\n",
       " '上除',\n",
       " '上須',\n",
       " '上黃化',\n",
       " '下一代',\n",
       " '下位',\n",
       " '下供',\n",
       " '下列',\n",
       " '下午',\n",
       " '下半年',\n",
       " '下均',\n",
       " '下垂',\n",
       " '下將',\n",
       " '下山',\n",
       " '下己',\n",
       " '下播種',\n",
       " '下方',\n",
       " '下旬',\n",
       " '下易',\n",
       " '下易產生',\n",
       " '下會',\n",
       " '下會產生',\n",
       " '下期',\n",
       " '下極',\n",
       " '下次',\n",
       " '下產生',\n",
       " '下田',\n",
       " '下端',\n",
       " '下葉鞘',\n",
       " '下藥',\n",
       " '下表',\n",
       " '下表中',\n",
       " '下載',\n",
       " '下述',\n",
       " '下部',\n",
       " '下開',\n",
       " '下降',\n",
       " '下陷',\n",
       " '下雨',\n",
       " '下面',\n",
       " '不下',\n",
       " '不久',\n",
       " '不予',\n",
       " '不二',\n",
       " '不但',\n",
       " '不佳',\n",
       " '不佳及',\n",
       " '不佳時',\n",
       " '不來',\n",
       " '不僅',\n",
       " '不像',\n",
       " '不償失',\n",
       " '不全',\n",
       " '不具',\n",
       " '不再',\n",
       " '不利',\n",
       " '不到',\n",
       " '不勾頭',\n",
       " '不及',\n",
       " '不可',\n",
       " '不同',\n",
       " '不善',\n",
       " '不堪',\n",
       " '不外乎',\n",
       " '不大',\n",
       " '不如',\n",
       " '不定',\n",
       " '不宜',\n",
       " '不容',\n",
       " '不少',\n",
       " '不展',\n",
       " '不常見',\n",
       " '不建議',\n",
       " '不得',\n",
       " '不必',\n",
       " '不慎',\n",
       " '不應',\n",
       " '不持續',\n",
       " '不整',\n",
       " '不斷',\n",
       " '不明',\n",
       " '不易',\n",
       " '不是',\n",
       " '不時',\n",
       " '不會',\n",
       " '不會產生',\n",
       " '不會重',\n",
       " '不正',\n",
       " '不用',\n",
       " '不當',\n",
       " '不盡',\n",
       " '不稔',\n",
       " '不管',\n",
       " '不絕',\n",
       " '不織布',\n",
       " '不能',\n",
       " '不致',\n",
       " '不良',\n",
       " '不著果',\n",
       " '不表現',\n",
       " '不要',\n",
       " '不見',\n",
       " '不規則',\n",
       " '不論',\n",
       " '不論行',\n",
       " '不足',\n",
       " '不通',\n",
       " '不過',\n",
       " '不過量',\n",
       " '不遠',\n",
       " '不錯',\n",
       " '不間',\n",
       " '不飛翔',\n",
       " '不飽滿',\n",
       " '不高',\n",
       " '且僅',\n",
       " '且務必',\n",
       " '且慢',\n",
       " '且施',\n",
       " '且易',\n",
       " '且易降',\n",
       " '且晨間',\n",
       " '且會',\n",
       " '且果',\n",
       " '且現',\n",
       " '且逢蕉株',\n",
       " '且須',\n",
       " '世代',\n",
       " '世界',\n",
       " '世界性',\n",
       " '世紀',\n",
       " '丙基喜樂松',\n",
       " '丟棄',\n",
       " '並上',\n",
       " '並不',\n",
       " '並不發生',\n",
       " '並不顯',\n",
       " '並且',\n",
       " '並仔細',\n",
       " '並仔細將',\n",
       " '並以',\n",
       " '並使',\n",
       " '並依',\n",
       " '並依其',\n",
       " '並依據',\n",
       " '並保護',\n",
       " '並保護天',\n",
       " '並傳',\n",
       " '並傳播',\n",
       " '並出',\n",
       " '並出現',\n",
       " '並分次',\n",
       " '並加',\n",
       " '並加強',\n",
       " '並勇',\n",
       " '並務',\n",
       " '並務必',\n",
       " '並勿',\n",
       " '並參考',\n",
       " '並及',\n",
       " '並可',\n",
       " '並可作',\n",
       " '並同時',\n",
       " '並向',\n",
       " '並向果',\n",
       " '並呈萎',\n",
       " '並噴施',\n",
       " '並嚴',\n",
       " '並嚴格',\n",
       " '並因',\n",
       " '並在',\n",
       " '並在種',\n",
       " '並在終',\n",
       " '並均勻',\n",
       " '並增',\n",
       " '並委由清',\n",
       " '並宜',\n",
       " '並將',\n",
       " '並將果',\n",
       " '並將藥',\n",
       " '並已',\n",
       " '並常圍',\n",
       " '並常腫',\n",
       " '並建議',\n",
       " '並影響',\n",
       " '並從病',\n",
       " '並徹底',\n",
       " '並應',\n",
       " '並應加',\n",
       " '並應用',\n",
       " '並懸掛',\n",
       " '並持續',\n",
       " '並指導',\n",
       " '並採',\n",
       " '並採取',\n",
       " '並散',\n",
       " '並於一',\n",
       " '並於主幹',\n",
       " '並於後續',\n",
       " '並於採',\n",
       " '並於施藥',\n",
       " '並於果',\n",
       " '並於田間',\n",
       " '並於終',\n",
       " '並於開',\n",
       " '並曝曬',\n",
       " '並曾',\n",
       " '並會',\n",
       " '並會長',\n",
       " '並有',\n",
       " '並未',\n",
       " '並每',\n",
       " '並決定',\n",
       " '並流膠',\n",
       " '並減',\n",
       " '並潛伏',\n",
       " '並無',\n",
       " '並無抗',\n",
       " '並無攜',\n",
       " '並無黃色',\n",
       " '並燒',\n",
       " '並特別',\n",
       " '並產',\n",
       " '並產卵',\n",
       " '並產生',\n",
       " '並盡量',\n",
       " '並確',\n",
       " '並確切',\n",
       " '並確實',\n",
       " '並立',\n",
       " '並給予',\n",
       " '並聯合',\n",
       " '並自',\n",
       " '並與',\n",
       " '並與縣',\n",
       " '並行',\n",
       " '並補施',\n",
       " '並補植',\n",
       " '並褐化',\n",
       " '並視',\n",
       " '並請',\n",
       " '並請務必',\n",
       " '並輪流',\n",
       " '並輪用',\n",
       " '並轉',\n",
       " '並逐漸',\n",
       " '並通報',\n",
       " '並進',\n",
       " '並進入',\n",
       " '並進行',\n",
       " '並達',\n",
       " '並適',\n",
       " '並適法',\n",
       " '並適當',\n",
       " '並適量',\n",
       " '並選',\n",
       " '並選擇',\n",
       " '並選用',\n",
       " '並選留',\n",
       " '並避開',\n",
       " '並酌',\n",
       " '並針',\n",
       " '並長',\n",
       " '並關閉',\n",
       " '並隨即',\n",
       " '並隨時',\n",
       " '並隨葉脈',\n",
       " '並需',\n",
       " '並非',\n",
       " '並食',\n",
       " '並鼓勵',\n",
       " '中下旬',\n",
       " '中之卵',\n",
       " '中之果',\n",
       " '中之落',\n",
       " '中以',\n",
       " '中任',\n",
       " '中作',\n",
       " '中供',\n",
       " '中化',\n",
       " '中北部',\n",
       " '中區',\n",
       " '中午',\n",
       " '中南部',\n",
       " '中及',\n",
       " '中和液',\n",
       " '中噴藥',\n",
       " '中埔',\n",
       " '中場',\n",
       " '中場籲',\n",
       " '中大果期',\n",
       " '中央',\n",
       " '中始',\n",
       " '中小',\n",
       " '中常',\n",
       " '中度',\n",
       " '中往',\n",
       " '中後期',\n",
       " '中心',\n",
       " '中所',\n",
       " '中抗',\n",
       " '中旬',\n",
       " '中是',\n",
       " '中期',\n",
       " '中果',\n",
       " '中果期',\n",
       " '中株',\n",
       " '中株期',\n",
       " '中殘留',\n",
       " '中段',\n",
       " '中毒',\n",
       " '中水',\n",
       " '中產卵',\n",
       " '中秋',\n",
       " '中等',\n",
       " '中籲',\n",
       " '中結',\n",
       " '中縣',\n",
       " '中脈',\n",
       " '中華民國',\n",
       " '中蕉',\n",
       " '中該',\n",
       " '中誘',\n",
       " '中農',\n",
       " '中達',\n",
       " '中部',\n",
       " '中針',\n",
       " '中間',\n",
       " '中闊',\n",
       " '中髓',\n",
       " '串飽度',\n",
       " '主動',\n",
       " '主因',\n",
       " '主幹',\n",
       " '主幹樹',\n",
       " '主持人',\n",
       " '主梗穗',\n",
       " '主產區',\n",
       " '主管',\n",
       " '主脈',\n",
       " '主要',\n",
       " '主辦',\n",
       " '乃力松',\n",
       " '乃是',\n",
       " '乃為',\n",
       " '久旱',\n",
       " '久旱不雨',\n",
       " '之一',\n",
       " '之下',\n",
       " '之中',\n",
       " '之久',\n",
       " '之以',\n",
       " '之依據',\n",
       " '之側',\n",
       " '之傳播',\n",
       " '之傳染',\n",
       " '之前',\n",
       " '之劑',\n",
       " '之務為',\n",
       " '之區域',\n",
       " '之協助',\n",
       " '之卵',\n",
       " '之卵粒',\n",
       " '之品',\n",
       " '之品種',\n",
       " '之品質',\n",
       " '之園區',\n",
       " '之圓圈',\n",
       " '之圓形',\n",
       " '之土',\n",
       " '之報',\n",
       " '之場',\n",
       " '之夏',\n",
       " '之夏蕉',\n",
       " '之外',\n",
       " '之大',\n",
       " '之天',\n",
       " '之好',\n",
       " '之季節',\n",
       " '之害蟲',\n",
       " '之小果',\n",
       " '之小點',\n",
       " '之展',\n",
       " '之山區',\n",
       " '之帶',\n",
       " '之幼蟲',\n",
       " '之後再',\n",
       " '之後擴',\n",
       " '之後轉',\n",
       " '之感病',\n",
       " '之成',\n",
       " '之成敗',\n",
       " '之成蟲',\n",
       " '之效',\n",
       " '之明',\n",
       " '之明顯',\n",
       " '之時',\n",
       " '之時期',\n",
       " '之時間',\n",
       " '之有',\n",
       " '之木',\n",
       " '之果',\n",
       " '之果園',\n",
       " '之果實',\n",
       " '之枝條',\n",
       " '之根際',\n",
       " '之桃園',\n",
       " '之梨穗',\n",
       " '之毒',\n",
       " '之氣候',\n",
       " '之氣溫',\n",
       " '之災害',\n",
       " '之為害',\n",
       " '之環境',\n",
       " '之生',\n",
       " '之生長',\n",
       " '之產生',\n",
       " '之產量',\n",
       " '之用',\n",
       " '之田區',\n",
       " '之田區須',\n",
       " '之田園',\n",
       " '之田間',\n",
       " '之病',\n",
       " '之登',\n",
       " '之登記',\n",
       " '之發',\n",
       " '之省',\n",
       " '之秧',\n",
       " '之稀釋',\n",
       " '之稔',\n",
       " '之種',\n",
       " '之稻',\n",
       " '之粒劑',\n",
       " '之系',\n",
       " '之細菌性',\n",
       " '之細長',\n",
       " '之經濟',\n",
       " '之緊',\n",
       " '之花穗',\n",
       " ...]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "ebe26f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from scipy import spatial\n",
    "## setting\n",
    "vector_dim = 200\n",
    "window_size = 5\n",
    "min_count = 1\n",
    "training_iter = 20\n",
    "\n",
    "## model\n",
    "word2vec_model = Word2Vec(sentences=df2list,\n",
    "                          vector_size=vector_dim, window=window_size, \n",
    "                          min_count=min_count, epochs=training_iter)\n",
    "# index to word\n",
    "index_to_word = word2vec_model.wv.index_to_key  # len(word2vec_model.wv.index2word) = 8659\n",
    "# index to vectors\n",
    "index2vec = word2vec_model.wv.vectors # word2vec_model.wv.vectors.shape = (8659, 100)\n",
    "\n",
    "def preprocess(s):\n",
    "    return [i.lower() for i in s.split()]\n",
    "def get_vector(s):\n",
    "    for i in preprocess(s):\n",
    "        try:\n",
    "            values = np.sum(np.array([word2vec_model.wv[i]]), axis=0)#Change\n",
    "        except KeyError:\n",
    "            c = 0\n",
    "    return values\n",
    "\n",
    "word2vec_feature = np.array([])\n",
    "for i in np.arange(len(cut_corpus)):\n",
    "    if word2vec_feature.size == 0:\n",
    "        word2vec_feature = np.array([get_vector(cut_corpus[i])])\n",
    "    else:\n",
    "        # concat the two vectors by different columns\n",
    "        word2vec_feature = np.concatenate((word2vec_feature,np.array([get_vector(cut_corpus[i])])), axis = 0)\n",
    "\n",
    "# word2vec_feature.shape = (560, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "819e8a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313040\n",
      "1383\n",
      "313040\n"
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "pair_list = []\n",
    "#Deprecated\n",
    "for fname1 in txt_fnames:\n",
    "    for fname2 in txt_fnames:\n",
    "        if(fname1 == fname2):continue\n",
    "        else:\n",
    "            labels[(fname1,fname2)] = 0\n",
    "            pair_list.append((fname1,fname2))\n",
    "corr_list = open('TrainLabel.csv', \"r\",encoding='UTF-8-sig')\n",
    "corr = corr_list.read()\n",
    "corr_line_sep = corr.splitlines()\n",
    "#Training label\n",
    "for line in corr_line_sep[1:]:\n",
    "    l = line.split(',')\n",
    "    labels[(l[0],l[1])] = 1\n",
    "print(len(labels))\n",
    "print(sum(labels.values()))\n",
    "print(len(pair_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "95a21fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313040\n"
     ]
    }
   ],
   "source": [
    "pos_pair_list = []\n",
    "pos_labels = set() #faster lookup to filter out positive pairs, not used elsewhere\n",
    "#All the associated article pairs given by train label\n",
    "for line in corr_line_sep[1:]:\n",
    "    l = line.split(',')\n",
    "    pos_pair_list.append((l[0],l[1]))\n",
    "    pos_labels.add((l[0],l[1]))\n",
    "neg_pair_list = []\n",
    "#Other pairs with no association\n",
    "for fname1 in txt_fnames:\n",
    "    for fname2 in txt_fnames:\n",
    "        if(fname1 == fname2):continue\n",
    "        if((fname1,fname2) not in pos_labels): #Filter out positive pairs\n",
    "            neg_pair_list.append((fname1,fname2))\n",
    "print(len(pos_pair_list)+len(neg_pair_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8d43ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# decide which feature you want, tfidf or countvector or others\n",
    "def construct_input_vector(adapted_vector, tokenized_df, pos_pair_list, neg_pair_list):\n",
    "    pl = len(pos_pair_list) # Number of positive pairs\n",
    "    neg_keys = random.sample(neg_pair_list,pl) # same length of negative pairs\n",
    "    sample_labels = {}\n",
    "    for key in neg_keys:sample_labels[key] = 0\n",
    "    for key in pos_pair_list:sample_labels[key] = 1\n",
    "    sample_pair_list = pos_pair_list + neg_keys\n",
    "    sample_labels_list = []\n",
    "    input_vectors = np.array([])\n",
    "    for i in np.arange(len(sample_pair_list)):\n",
    "        Test, Ref = sample_pair_list[i] # order of docs\n",
    "        sample_labels_list.append(sample_labels[(Test,Ref)]) # labels\n",
    "        Test_vec = adapted_vector[tokenized_df[tokenized_df['name']==Test].index[0]] # from order of doc to find out the order of vectors\n",
    "        Ref_vec = adapted_vector[tokenized_df[tokenized_df['name']==Ref].index[0]] # same\n",
    "        temp_vectors = np.concatenate(([Test_vec],[Ref_vec]), axis = 1) # concat the two vectors in same row\n",
    "        if input_vectors.size == 0:\n",
    "            input_vectors = temp_vectors\n",
    "        else:\n",
    "            input_vectors = np.concatenate((input_vectors,temp_vectors)) # concat the two vectors by different columns\n",
    "    return input_vectors, sample_labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75664f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vectors0, sample_labels_list0 = construct_input_vector(tfidfs, df, pos_pair_list, neg_pair_list)\n",
    "# input_vectors0.shape, len(sample_labels_list0) = (2766, 15122), 2766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0901bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vectors1, sample_labels_list1 = construct_input_vector(counts, df, pos_pair_list, neg_pair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "146af23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vectors2, sample_labels_list2 = construct_input_vector(word2vec_feature, df, pos_pair_list, neg_pair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97d54cdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1284/852056315.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# using these code as embedding features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform',\n\u001b[0m\u001b[0;32m      3\u001b[0m                        \u001b[0membeddings_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                        embeddings_constraint=None, mask_zero=False, input_length=None)\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex2vec\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# using these code as embedding features\n",
    "keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform',\n",
    "                       embeddings_regularizer=None, activity_regularizer=None,\n",
    "                       embeddings_constraint=None, mask_zero=False, input_length=None)\n",
    "model.add(Embedding(index2vec.shape[0], index2vec.shape[1], weights=[index2vec], trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd1915ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2766, 21292), (2766, 21292), (2766, 400))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vectors0.shape,input_vectors1.shape,input_vectors2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a70b1",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c0aee5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560\n"
     ]
    }
   ],
   "source": [
    "#df.iloc[0]['name']\n",
    "#tfidf_dict = {}\n",
    "#for idx,vec in enumerate(tfidfs):\n",
    "    #tfidf_dict[df.iloc[idx]['name']] = vec\n",
    "#print(len(tfidf_dict))\n",
    "w2v_dict = {}\n",
    "for idx,vec in enumerate(word2vec_feature):\n",
    "    w2v_dict[df.iloc[idx]['name']] = vec\n",
    "print(len(w2v_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "d8d908b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "# Dataset\n",
    "#Custom dataset, currently generates a 50/50 split of positive and negative sample\n",
    "#To change the split, change the second variable of random.sample and the __len__ function accordingly\n",
    "class PartDataset(data.Dataset):\n",
    "    def __init__(self, pos_pair_list, neg_pair_list, vectors):\n",
    "        self.l = len(pos_pair_list)#Number of positive pairs\n",
    "        neg_keys = random.sample(neg_pair_list,self.l)#Sample negative pairs, change the second variable to change the split\n",
    "        self.labels = {}\n",
    "        for key in neg_keys:self.labels[key] = 0\n",
    "        for key in pos_pair_list:self.labels[key] = 1\n",
    "        self.pair_list = pos_pair_list+neg_keys\n",
    "        self.vectors = vectors\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.l*2\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        Test,Ref = self.pair_list[idx]\n",
    "        label = self.labels[(Test,Ref)]\n",
    "        #comb_vector = self.vectors[Test] + self.vectors[Ref]\n",
    "        comb_vector = np.concatenate((self.vectors[Test], self.vectors[Ref]), axis=None)\n",
    "        return torch.tensor(comb_vector), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "5f2fd099",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdim_tfidf = len(tfidfs[0])\n",
    "class TfIdfNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TfIdfNeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(inputdim_tfidf*2, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 56),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(56, 2),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "inputdim_w2v = len(word2vec_feature[0])\n",
    "class w2vNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(w2vNeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(inputdim_w2v*2, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(50, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(20, 2),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "06b24d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = PartDataset(pos_pair_list, neg_pair_list, tfidf_dict)\n",
    "#test_dataset = PartDataset(pos_pair_list, neg_pair_list, tfidf_dict)\n",
    "train_dataset = PartDataset(pos_pair_list, neg_pair_list, w2v_dict)\n",
    "test_dataset = PartDataset(pos_pair_list, neg_pair_list, w2v_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "b896f785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Check\n",
      "tensor([1, 0, 0, 1]) tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "tfidf_train_dataloader = data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "tfidf_test_dataloader = data.DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "tfidf_dataloader_dict = {'train': tfidf_train_dataloader, 'test': tfidf_test_dataloader}\n",
    "\n",
    "# Operation Check\n",
    "print('Operation Check')\n",
    "batch_iterator = iter(tfidf_train_dataloader)\n",
    "inputs, label = next(batch_iterator)\n",
    "print(label,inputs[0][0:200]==inputs[0][200:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "4c347642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2vNeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=50, out_features=20, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=20, out_features=2, bias=True)\n",
      "    (10): Softmax(dim=None)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#net = TfIdfNeuralNetwork()\n",
    "net = w2vNeuralNetwork()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=0.001, momentum=0.9)\n",
    "#cross entropy loss and stochastic gradient descent\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "9af65130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def train_model(net, dataloader_dict, criterion, optimizer, num_epoch):\n",
    "    \n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(net.state_dict())\n",
    "    best_acc = 0.0\n",
    "    net = net.to(device)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epoch))\n",
    "        print('-'*20)\n",
    "        \n",
    "        for phase in ['train', 'test']:\n",
    "            \n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "                \n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "            \n",
    "            #tqdm for progress bar\n",
    "            for inputs, labels in tqdm(dataloader_dict[phase]):\n",
    "                inputs = inputs.type(torch.FloatTensor).to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = net(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "                    \n",
    "            epoch_loss = epoch_loss / len(dataloader_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloader_dict[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(net.state_dict())\n",
    "                print(time.time())\n",
    "                torch.save(net.state_dict(), 'best_checkpoint_last_w2v.pth')\n",
    "                \n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    net.load_state_dict(best_model_wts)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "efa3a7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0970aead54c4838b725ddc6e87cc610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6933 Acc: 0.5011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7289dc871f224d1d98ac73751a569096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6927 Acc: 0.5365\n",
      "1639237204.2761912\n",
      "Epoch 2/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2df073948c4a4483f169659202696a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6930 Acc: 0.5116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8cff14ad7845ff94b18ab06440b77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6926 Acc: 0.5253\n",
      "Epoch 3/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9edaad385e411f90a7a250213f7366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6929 Acc: 0.5134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20b0615b4d746398efe7def609880ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6923 Acc: 0.5246\n",
      "Epoch 4/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c52a68d982c42ebab9da02310aeeb87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6933 Acc: 0.5080\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c5b5f78c804782ae273c1abadfd09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6922 Acc: 0.5365\n",
      "Epoch 5/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305426f1826347aaa4a505a047cd9aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6927 Acc: 0.5087\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b1806a7bea46b2990bbf4a73b96f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6921 Acc: 0.5087\n",
      "Epoch 6/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e69edd1da24d9e93c718751a2ef7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6927 Acc: 0.5166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0810d326f934ea4aa7643cb81950258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6917 Acc: 0.5358\n",
      "Epoch 7/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31b292fdb8e45e4acebb8b2c566d986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6928 Acc: 0.5061\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4ded5e78724cf289a0d706847c9acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6915 Acc: 0.5358\n",
      "Epoch 8/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b618567460f7436a88474b78b8ef5812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6925 Acc: 0.5033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbc26c996c34d8a83fcd9a6354b8508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6912 Acc: 0.5437\n",
      "1639237220.6942272\n",
      "Epoch 9/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6781122cc98c42e1a0f426499e57e769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6922 Acc: 0.5210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba4b6d9bf3f46e3b0abca511b549db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6910 Acc: 0.5372\n",
      "Epoch 10/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728c7fff4f5d4d0c90f43909fc78cb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6922 Acc: 0.5119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4be9a3d016d4376a4757711eef45940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6906 Acc: 0.5372\n",
      "Epoch 11/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae1fc7348a94327a26077e8426c2499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6912 Acc: 0.5304\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f01aca1e564003a1cb4a437b9567bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6900 Acc: 0.5434\n",
      "Epoch 12/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7967c386c8b043779aa236c25febc6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6918 Acc: 0.5137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba6b547dc7e44db8b2f3cce159e87cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6896 Acc: 0.5459\n",
      "1639237230.3803701\n",
      "Epoch 13/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fabf52b9c6447c961ebc821fbf35c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6909 Acc: 0.5325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a585c05d49422d8404b9f91f93efc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6892 Acc: 0.5456\n",
      "Epoch 14/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b939aa0d1914514a66272e23f1b2c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6909 Acc: 0.5264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0469201e3ab47aeb2edc4c068236680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6887 Acc: 0.5463\n",
      "1639237235.26337\n",
      "Epoch 15/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ea182503d64d4b830e7e5ae4b74589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6913 Acc: 0.5213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818f9bcd104147d3a7f3cc45f235ad1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6882 Acc: 0.5463\n",
      "Epoch 16/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbbf30325404548bc85fa156f818f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6895 Acc: 0.5278\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f460e938fa3647bd8e32d6ed67bb284d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6878 Acc: 0.5188\n",
      "Epoch 17/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fee9ffb0c04a10b7806e34b2e3649f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6900 Acc: 0.5249\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9acae72d2294922a265d47ecf4a0ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6869 Acc: 0.5492\n",
      "1639237241.8996494\n",
      "Epoch 18/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51744347fec54023af03bf9eee1bc4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6896 Acc: 0.5286\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fd055bce3647feabced285a07aac14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6868 Acc: 0.5177\n",
      "Epoch 19/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f1611bbb0545fd8ba2847afb9b2291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6888 Acc: 0.5257\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2383748585ba4fb0b0829ef3fc8e0692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6856 Acc: 0.5452\n",
      "Epoch 20/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7156752a28fb42bd95dd442077950799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6877 Acc: 0.5456\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1986f2b75e4c446a96636bde9be099ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6851 Acc: 0.5513\n",
      "1639237249.5876513\n",
      "Epoch 21/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77aa68b074174e21ba1b530cd38c9c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6884 Acc: 0.5329\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b6ffbc0732428a8a5585e473453b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6842 Acc: 0.5510\n",
      "Epoch 22/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f2849633464b05b014ae51f966f14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6878 Acc: 0.5282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a36f1ffc994617b8c060bb0d738288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6843 Acc: 0.5499\n",
      "Epoch 23/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4222e81ae8e749cba0142c6e34832696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6863 Acc: 0.5372\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05db761e5e6b4ad9be001d573fb11f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6835 Acc: 0.5506\n",
      "Epoch 24/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae402c139e01499e840f1ebcc44f88ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6879 Acc: 0.5437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a52199d5694c7cb33e78929ea40386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6823 Acc: 0.5510\n",
      "Epoch 25/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4046e43210034e53b560dd08c13559ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6861 Acc: 0.5358\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4e3ea760e1491b9fa416f66dfb9fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6821 Acc: 0.5513\n",
      "Epoch 26/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d3808cdc2b4dc7b6e0e4e5cf816a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6855 Acc: 0.5304\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b80d02b2c74b22b72d0f139f475726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6810 Acc: 0.5513\n",
      "Epoch 27/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e3d2e93b9746078e146b32eb878e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6845 Acc: 0.5416\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a234938af2c84feb90231ca99904da48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6802 Acc: 0.5586\n",
      "1639237265.7473845\n",
      "Epoch 28/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca9902c06a641ac8ebf5ec98fd7ed03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6836 Acc: 0.5474\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7e5f6e98884b538e9d9d2feda0947d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6802 Acc: 0.5586\n",
      "Epoch 29/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84dbdd0fdb443eca80005c6915b574b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6832 Acc: 0.5524\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac2c2aaab85407f9658bdb13f10c032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6788 Acc: 0.5557\n",
      "Epoch 30/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4531ed92846941bb9a0583b756f9f8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6833 Acc: 0.5376\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323c18a587af4f59a9f443a9c8a1f2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6794 Acc: 0.5293\n",
      "Epoch 31/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3619a76f07464059935467c1ebd017f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6839 Acc: 0.5148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e455cc4930fa4cafa65b63c8c8f15541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6789 Acc: 0.5578\n",
      "Epoch 32/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2188967f084a11bf6b8444a0a0bb51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6826 Acc: 0.5441\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f73e9138cb247d79f710d2e975161b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6784 Acc: 0.5575\n",
      "Epoch 33/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142d31ce1aad4b199507efdf6a720597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6829 Acc: 0.5369\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4628b5460e78499faa6b51898abff137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6779 Acc: 0.5325\n",
      "Epoch 34/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5746068855d94e40af9faf5c1875fefe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6826 Acc: 0.5242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e80efb1e2f4bafb8682621523bce74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6773 Acc: 0.5593\n",
      "1639237282.3816361\n",
      "Epoch 35/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e8e5b20b3d4c368b6d44b5597cf9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6821 Acc: 0.5466\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1a71fe82f642e6a085799189e2bace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6772 Acc: 0.5575\n",
      "Epoch 36/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5859076796407bb0417a3c4287b787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6808 Acc: 0.5459\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84165ce39d1b4561a20bc44f6c509a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6776 Acc: 0.5322\n",
      "Epoch 37/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2bccee59b24fc9ad9ac3facbe2cdb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6815 Acc: 0.5394\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037c7b35809c431f91434777db8102d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6762 Acc: 0.5593\n",
      "Epoch 38/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37433babfac245828f019a116870fbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6810 Acc: 0.5278\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30356e8fc7f142a8b65a6bb207ec6bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6765 Acc: 0.5582\n",
      "Epoch 39/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4424f4e0e2b94520b2bdb68d4c5aaa13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6796 Acc: 0.5401\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fe54b9d69c444f9e03cb7eae3ec974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6757 Acc: 0.5604\n",
      "1639237294.223858\n",
      "Epoch 40/40\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea9f0edcc414e12ae4cec91b351b403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6781 Acc: 0.5488\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8b9afec8b548e896f04ec7b39b81b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6754 Acc: 0.5589\n",
      "Training complete in 1m 35s\n",
      "Best val Acc: 0.560376\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 40\n",
    "net = train_model(net, tfidf_dataloader_dict, criterion, optimizer, num_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fed10f",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509203c",
   "metadata": {},
   "source": [
    "#### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "5168e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'Stage_2\\dataPublicComplete_s2\\dataPublicComplete'\n",
    "txt_fnames = [splitext(f)[0] for f in listdir(datapath) if isfile(join(datapath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "f0406180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "df = pd.DataFrame([])\n",
    "for fname in txt_fnames:\n",
    "    txt = open(datapath+'/'+fname+'.txt', \"r\",encoding=\"utf-8\")\n",
    "    content = txt.read()\n",
    "    df = pd.concat([df, pd.Series([jieba.lcut(content, cut_all=False)])], axis = 0)\n",
    "df.columns = ['tokenization']\n",
    "df['name'] = txt_fnames\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "6b1aeb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping all the docs\n",
    "for index, row in df.iterrows():\n",
    "    row['tokenization'] = keyword_normalization(df.iloc[index]['tokenization'], vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "920393cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat tokenized text with space\n",
    "df2list = df.tokenization.tolist()\n",
    "cut_corpus = []\n",
    "for i in df2list:\n",
    "    cut_corpus.append(' '.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "6799fd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cut_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "6c2b0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing input\n",
    "# for CountVectorizer module to calculate the term frequency\n",
    "counts = count_vect.transform(cut_corpus).toarray()\n",
    "count_feature = count_vect.get_feature_names()\n",
    "# for TfidfVectorizer module to convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "tfidfs = tfidf_vect.transform(cut_corpus).toarray()\n",
    "tfidf_feature = tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "4c98076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_feature = np.array([])\n",
    "for i in np.arange(len(cut_corpus)):\n",
    "    if word2vec_feature.size == 0:\n",
    "        word2vec_feature = np.array([get_vector(cut_corpus[i])])\n",
    "    else:\n",
    "        # concat the two vectors by different columns\n",
    "        word2vec_feature = np.concatenate((word2vec_feature,np.array([get_vector(cut_corpus[i])])), axis = 0)\n",
    "# word2vec_feature.shape = (421, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2082fbe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1284/852056315.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# using these code as embedding features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform',\n\u001b[0m\u001b[0;32m      3\u001b[0m                        \u001b[0membeddings_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                        embeddings_constraint=None, mask_zero=False, input_length=None)\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex2vec\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# using these code as embedding features\n",
    "keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform',\n",
    "                       embeddings_regularizer=None, activity_regularizer=None,\n",
    "                       embeddings_constraint=None, mask_zero=False, input_length=None)\n",
    "model.add(Embedding(index2vec.shape[0], index2vec.shape[1], weights=[index2vec], trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "a6075a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "pair_list = []\n",
    "#Deprecated\n",
    "for fname1 in txt_fnames:\n",
    "    for fname2 in txt_fnames:\n",
    "        if(fname1 == fname2):continue\n",
    "        else:\n",
    "            labels[(fname1,fname2)] = 0\n",
    "            pair_list.append((fname1,fname2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3e94c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# decide which feature you want, tfidf or countvector or others\n",
    "def construct_test_input_vector(adapted_vector, tokenized_df, test_pair_list):\n",
    "    input_vectors = np.array([])\n",
    "    for i in np.arange(len(test_pair_list)):\n",
    "        Test, Ref = test_pair_list[i] # order of docs\n",
    "        Test_vec = adapted_vector[tokenized_df[tokenized_df['name']==Test].index[0]] # from order of doc to find out the order of vectors\n",
    "        Ref_vec = adapted_vector[tokenized_df[tokenized_df['name']==Ref].index[0]] # same\n",
    "        temp_vectors = np.concatenate(([Test_vec],[Ref_vec]), axis = 1) # concat the two vectors in same row\n",
    "        if input_vectors.size == 0:\n",
    "            input_vectors = temp_vectors\n",
    "        else:\n",
    "            input_vectors = np.concatenate((input_vectors,temp_vectors)) # concat the two vectors by different columns\n",
    "    return input_vectors\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a5ea7751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = construct_test_input_vector(tfidfs, df, pair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "c1b700e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421\n",
      "421\n"
     ]
    }
   ],
   "source": [
    "tfidf_test_dict = {}\n",
    "for idx,vec in enumerate(tfidfs):\n",
    "    tfidf_test_dict[df.iloc[idx]['name']] = vec\n",
    "print(len(tfidf_test_dict))\n",
    "w2v_test_dict = {}\n",
    "for idx,vec in enumerate(word2vec_feature):\n",
    "    w2v_test_dict[df.iloc[idx]['name']] = vec\n",
    "print(len(w2v_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "5b10b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "with torch.no_grad():\n",
    "    for test,ref in pair_list:\n",
    "        input_vec = torch.tensor(np.concatenate((w2v_test_dict[test], w2v_test_dict[ref]), axis=None))\n",
    "        input_vec = input_vec.type(torch.FloatTensor).to(device)\n",
    "        lbl = net(input_vec)\n",
    "        out.append([(test,ref),lbl.cpu()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "673978a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('1001', '1004'), tensor([0.1827, 0.8173])],\n",
       " [('1001', '1006'), tensor([0.0926, 0.9074])],\n",
       " [('1001', '1008'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1009'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1012'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1014'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1019'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '102'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1022'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1024'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1027'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1028'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1029'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1032'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1034'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1036'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1038'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1040'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1048'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1050'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1051'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1053'), tensor([0.0389, 0.9611])],\n",
       " [('1001', '1060'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1061'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1062'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1063'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1064'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1070'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1072'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1080'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1081'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1084'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1085'), tensor([0.1798, 0.8202])],\n",
       " [('1001', '1089'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '109'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1091'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1092'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1094'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1095'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1097'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1098'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1105'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1106'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '111'), tensor([0.1539, 0.8461])],\n",
       " [('1001', '1113'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '112'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1121'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1123'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1124'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1129'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1131'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1135'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1137'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '114'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1140'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1143'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1156'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1158'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '116'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1162'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1163'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1164'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1175'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1177'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1182'), tensor([0.3039, 0.6961])],\n",
       " [('1001', '1188'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1196'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1197'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1201'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1202'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1203'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1204'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1205'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1209'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1213'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1216'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1219'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '122'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1225'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1227'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '123'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1231'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1233'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1238'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '124'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1245'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '125'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1251'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1252'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1254'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1268'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1269'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1273'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1277'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '128'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1284'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1285'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1287'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1288'), tensor([0.2297, 0.7703])],\n",
       " [('1001', '1295'), tensor([0.2297, 0.7703])]]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "127c3e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980 176820\n"
     ]
    }
   ],
   "source": [
    "better = []\n",
    "for o in out:\n",
    "    if(o[1][1] > 0.84):better.append(o[0])\n",
    "print(len(better),len(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefac875",
   "metadata": {},
   "source": [
    "#### classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621427c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "5a9b014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "print(len(better))\n",
    "with open('val_w2v.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow([\"Test\"]+[\"Reference\"])\n",
    "    for row in better:  \n",
    "        spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d72ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
