{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "103a4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "import os, glob, time, copy, random, zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c05b6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join,splitext\n",
    "datapath = 'Stage_2\\dataPublicComplete_s2\\dataPublicComplete'\n",
    "txt_fnames = [splitext(f)[0] for f in listdir(datapath) if isfile(join(datapath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "90e45dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_list = open('Keywords/02crop.list.csv', \"r\",encoding='UTF-8-sig')\n",
    "crop = crop_list.read()\n",
    "crop_line_sep = crop.splitlines()\n",
    "\n",
    "pest_list = open('Keywords/02pest.list.csv', \"r\",encoding='UTF-8-sig')\n",
    "pest = pest_list.read()\n",
    "pest_line_sep = pest.splitlines()\n",
    "\n",
    "chem_list = open('Keywords/02chem.list.csv', \"r\",encoding='UTF-8-sig')\n",
    "chem = chem_list.read()\n",
    "chem_line_sep = chem.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5fac3e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "vector_dict = {}\n",
    "for idx,line in enumerate(chain(crop_line_sep,pest_line_sep,chem_line_sep)):\n",
    "    l = line.split(',')\n",
    "    for word in l:\n",
    "        if(word == ''):continue\n",
    "        jieba.add_word(word)\n",
    "        vector_dict[word] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b739aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = {}\n",
    "for fname in txt_fnames:\n",
    "    txt = open(datapath+'/'+fname+'.txt', \"r\",encoding=\"utf-8\")\n",
    "    content = txt.read()\n",
    "    seg_list = jieba.cut(content, cut_all=True)\n",
    "    vectors[fname] = [0]*764\n",
    "    for seg in seg_list:\n",
    "        if(seg in vector_dict):\n",
    "            vectors[fname][vector_dict[seg]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ef79f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2*764, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 20),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(20, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "05417d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork()\n",
    "net.load_state_dict(torch.load('best_checkpoint_last.pth'))\n",
    "net.eval()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e303af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "with torch.no_grad():\n",
    "    for fname1 in txt_fnames:\n",
    "        for fname2 in txt_fnames:\n",
    "            if(fname1 == fname2):continue\n",
    "            else:\n",
    "                comb_vec = torch.tensor(vectors[fname1]+vectors[fname2])\n",
    "                comb_vec = comb_vec.type(torch.FloatTensor).to(device)\n",
    "                lbl = net(comb_vec)\n",
    "                out.append([(fname1,fname2),lbl.cpu()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f3667d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "better = []\n",
    "for o in out:\n",
    "    if(o[1][1] > 0):\n",
    "        better.append(o[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6b17544b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6298\n"
     ]
    }
   ],
   "source": [
    "print(len(better))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4f69b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('val.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow([\"Test\"]+[\"Reference\"])\n",
    "    for row in better:  \n",
    "        spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75760572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
